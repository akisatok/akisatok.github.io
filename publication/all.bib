
@article{Takahashi2020,
abstract={The advancement of technology has resulted in a rapid increase in supernova (SN) discoveries. The Subaru/Hyper Suprime-Cam (HSC) transient survey, conducted from fall 2016 through spring 2017, yielded 1824 SN candidates. This gave rise to the need for fast type classification for spectroscopic follow-up and prompted us to develop a machine learning algorithm using a deep neural network (DNN) with highway layers. This machine is trained by actual observed cadence and filter combinations such that we can directly input the observed data array into the machine without any interpretation. We tested our model with a dataset from the LSST classification challenge (Deep Drilling Field). Our classifier scores an area under the curve (AUC) of 0.996 for binary classification (SN Ia or non-SN Ia) and 95.3% accuracy for three-class classification (SN Ia, SN Ibc, or SN II). Application of our binary classification to HSC transient data yields an AUC score of 0.925. With two weeks of HSC data since the first detection, this classifier achieves 78.1% accuracy for binary classification, and the accuracy increases to 84.2% with the full dataset. This paper discusses the potential use of machine learning for SN type classification purposes.},
author = {Ichiro Takahashi and Nao Suzuki and Naoki Yasuda and Akisato Kimura and Naonori Ueda and Naoki Yoshida},
doi = {10.1093/pasj/psaa082},
journal = {Publications of the Astronomical Society of Japan},
month = {aug},
publisher = {Oxford University Press (OUP)},
title = {{Photometric classification of the HSC transients through machine learning}},
year = {2020}
}
@inproceedings{WuICPR2020,
author = {Xiaomeng Wu and Akisato Kimura and Kunio Kashino and Seiichi Uchida},
booktitle = {IAPR International Conference on Pattern Recognition (ICPR2020)},
doi = {},
month = {},
pages = {},
title = {{Total whitening for online signature verification based on deep representation}},
year = {2020}
}
@inproceedings{MitsuzumiICIP2020,
author = {Yu Mitsuzumi and Go Irie and Akisato Kimura and Atsushi Nakazawa},
booktitle = {IEEE International Conference on Image Processing (ICIP2020)},
doi = {},
month = {oct},
pages = {},
title = {{A generative self-ensemble approach to simulated+unsupervised learning}},
year = {2020}
}
@inproceedings{OhishiICASSP2020,
author = {Yasunori Ohishi and Akisato Kimura and Takahito Kawanishi and Kunio Kashino and David Harwath and James Glass},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP2020)},
doi = {10.1109/ICASSP40776.2020.9053428},
month = {may},
pages = {},
title = {{Trilingual semantic embeddings of visually grounded speech with self-attention mechanisms}},
year = {2020}
}
@incollection{JSAI2020MIRU2020,
author = {洋一, 佐藤 and 徹, 玉木 and 昭悟, 木村},
journal = {人工知能学会誌},
number = {},
pages = {},
title = {企画セッション KS-02 「画像とAI」},
url = {},
volume = {},
month = {nov},
year = {2020}
}
@incollection{JSAI2020review,
author = {昭悟, 木村},
journal = {人工知能学会誌},
number = {},
pages = {},
title = {特集「2020年度人工知能学会全国大会（第34回）」にあたって},
url = {},
volume = {},
month = {nov},
year = {2020}
}
@incollection{JSAI2020preview,
author = {木村, 昭悟},
journal = {人工知能学会誌},
number = {},
pages = {},
title = {巻頭言： 2020年，夏，熊本},
url = {},
volume = {},
month = {nov},
year = {2019}
}
@inproceedings{8683142,
abstract = {Sounds provide us with vast amounts of information about surrounding objects and can even remind us visual images of them. Is it possible to implement this noteworthy human ability on machines? In this paper, we study a new task that consists of predicting image recognition results in the form of semantic segmentation with given multichannel audio signals. Our approach uses a convolutional neural network that is designed to directly output semantic segmentation results by taking audio features as its inputs. A bilinear feature fusion scheme is incorporated that efficiently models underlying higher-order interactions between audio and visual sources. Experimental evaluations with both synthetic and real sound datasets show that our approach can recover the desired segmented images reasonably well.},
author = {Irie, Go and Ostrek, Mirela and Wang, Haochen and Kameoka, Hirokazu and Kimura, Akisato and Kawanishi, Takahito and Kashino, Kunio},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2019.8683142},
issn = {2379-190X},
keywords = {audio signal processing,convolutional neural nets},
month = {may},
pages = {3961--3964},
title = {{Seeing through Sounds: Predicting Visual Semantic Segmentation Results from Multichannel Audio Signals}},
year = {2019}
}
@inproceedings{8683036,
abstract = {We propose a neural network-based framework for learning local representations of multivariate time series, and demonstrate its effectiveness for online signature verification. In contrast to related works that optimize a global distance objective, we incorporate a Siamese network into dynamic time warping (DTW), leading to a novel prewarping Siamese network (PSN) optimized with a local embedding loss. PSN learns a feature space that preserves the temporal location-wise distances of local structures. Local embedding, along with the alignment conditions of DTW, imposes a temporal consistency constraint on the sequence-level distance measure while achieving invariance as regards non-linear distortions. Validation on online signature verification datasets demonstrates the advantage of our framework over existing techniques that use either handcrafted or learned feature representations.},
author = {Wu, Xiaomeng and Kimura, Akisato and Uchida, Seiichi and Kashino, Kunio},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2019.8683036},
issn = {2379-190X},
keywords = {feature extraction,handwriting recognition,image r},
month = {may},
pages = {2467--2471},
title = {{Prewarping Siamese Network: Learning Local Representations for Online Signature Verification}},
year = {2019}
}
@techreport{2019,
author = {大石, 康智 and 木村, 昭悟 and 川西, 隆仁 and 柏野, 邦夫},
journal = {電子情報通信学会技術報告 PRMU},
number = {42},
pages = {1--6},
title = {画像を説明する多言語音声データを利用したクロスモーダル探索},
volume = {2019},
year = {2019}
}
@article{Yasuda2019,
abstract = {We present an overview of a deep transient survey of the COSMOS field with the Subaru Hyper Suprime-Cam (HSC). The survey was performed for the 1.77 deg{\$}{\^{}}2{\$} ultra-deep layer and 5.78 deg{\$}{\^{}}2{\$} deep layer in the Subaru Strategic Program over 6- and 4-month periods from 2016 to 2017, respectively. The ultra-deep layer shows a median depth per epoch of 26.4, 26.3, 26.0, 25.6, and 24.6 mag in {\$}g{\$}, {\$}r{\$}, {\$}i{\$}, {\$}z{\$}, and {\$}y{\$} bands, respectively; the deep layer is {\$}\backslashsim0.6{\$} mag shallower. In total, 1,824 supernova candidates were identified. Based on light curve fitting and derived light curve shape parameter, we classified 433 objects as Type Ia supernovae (SNe); among these candidates, 129 objects have spectroscopic or COSMOS2015 photometric redshifts and 58 objects are located at {\$}z {\textgreater} 1{\$}. Our unique dataset doubles the number of Type Ia SNe at {\$}z {\textgreater} 1{\$} and enables various time-domain analyses of Type II SNe, high redshift superluminous SNe, variable stars, and active galactic nuclei.},
author = {Yasuda, Naoki and Tanaka, Masaomi and Tominaga, Nozomu and Jiang, Ji-an and Moriya, Takashi J and Morokuma, Tomoki and Suzuki, Nao and Takahashi, Ichiro and Yamaguchi, Masaki S and Maeda, Keiichi and Sako, Masao and Ikeda, Shiro and Kimura, Akisato and Morii, Mikio and Ueda, Naonori and Yoshida, Naoki and Lee, Chien-Hsiu and Suyu, Sherry H and Komiyama, Yutaka and Regnault, Nicolas and Rubin, David},
doi = {10.1093/pasj/psz050},
issn = {0004-6264},
journal = {Publications of the Astronomical Society of Japan},
month = {jun},
publisher = {Oxford University Press (OUP)},
title = {{The Hyper Suprime-Cam SSP transient survey in COSMOS: Overview}},
year = {2019}
}
@inproceedings{Wu2019,
author = {Wu, Xiaomeng and Kimura, Akisato and Iwana, Brian Kenji and Uchida, Seiichi and Kashino, Kunio},
booktitle = {International Conference on Document Analysis and Recognition (ICDAR)},
title = {{Deep dynamic time warping: End-to-end local feature learning for online signature verification}},
year = {2019}
}
@incollection{Irie2019,
abstract = {Human beings can get a visual image of the surrounding environment from sounds they hear. Can we give similar capabilities to computers? In this article, we introduce our recent efforts in cross-media scene analysis applied to estimate the type, location, and visual shape of objects in a scene based only on sound sources recorded with multiple microphones.},
author = {Irie, Go and Kameoka, Hirokazu and Kimura, Akisato and Hiramatsu, Kaoru and Kashino, Kunio},
journal = {NTT Technical Review},
keywords = {cross media,deep learning,scene analysis},
number = {11},
pages = {35--40},
title = {{Cross-media Scene Analysis: Estimating Objects' Visuals Only from Audio}},
url = {https://www.ntt-review.jp/archive/ntttechnical.php?contents=ntr201811fa5.html},
volume = {16},
year = {2019}
}
@inproceedings{mukuta2018weakly,
author = {Mukuta, Yusuke and Kimura, Akisato and Adrian, David B and Ghahramani, Zoubin},
booktitle = {Thirty-Second AAAI Conference on Artificial Intelligence},
title = {{Weakly supervised collective feature learning from curated media}},
year = {2018}
}
@incollection{2018,
author = {木村, 昭悟},
journal = {人工知能},
title = {グローバルアイ [第 41 回]「短い勤務時間で優れた研究成果を数多く出すには」},
volume = {33},
year = {2018}
}
@inproceedings{Kimura2018,
abstract = {In this paper, we propose a simple but effective method for training neural networks with a limited amount of training data. Our approach inherits the idea of knowledge distillation that transfers knowledge from a deep or wide reference model to a shallow or narrow target model. The proposed method employs this idea to mimic predictions of reference estimators that are more robust against overfitting than the network we want to train. Different from almost all the previous work for knowledge distillation that requires a large amount of labeled training data, the proposed method requires only a small amount of training data. Instead, we introduce pseudo training examples that are optimized as a part of model parameters. Experimental results for several benchmark datasets demonstrate that the proposed method outperformed all the other baselines, such as naive training of the target model and standard knowledge distillation.},
author = {Kimura, Akisato and Ghahramani, Zoubin and Takeuchi, Koh and Iwata, Tomoharu and Ueda, Naonori},
booktitle = {British Machine Vision Conference (BMVC)},
title = {{Few-shot learning of neural networks from scratch by pseudo example optimization}},
url = {http://bmvc2018.org/contents/papers/0366.pdf},
year = {2018}
}
@incollection{2018a,
author = {入江, 豪 and 亀岡, 弘和 and 木村, 昭悟 and 平松, 薫 and 柏野, 邦夫},
journal = {NTT 技術ジャーナル},
number = {9},
pages = {24--28},
publisher = {電気通信協会},
title = {音から画像認識結果を予測するクロスメディア情景分析技術},
url = {https://www.ntt.co.jp/journal/1809/files/JN20180924.pdf},
volume = {30},
year = {2018}
}
@incollection{2018b,
author = {安倍, 満 and 木村, 昭悟 and 舩冨, 卓哉},
journal = {電子情報通信学会誌},
number = {10},
pages = {996--1003},
publisher = {電子情報通信学会},
title = {{パターン認識・メディア理解の基礎技術に関する Open Idea}},
url = {https://www.journal.ieice.org/bin/pdf{\_}link.php?fname=k101{\_}10{\_}996{\&}lang=J{\&}year=2018},
volume = {101},
year = {2018}
}
@techreport{2018c,
author = {木村, 昭悟 and Ghahramani, Zoubin and 竹内, 孝 and 岩田, 具治 and 上田, 修功},
booktitle = {人工知能学会全国大会},
title = {疑似学習サンプル最適化によるニューラルネットワークの少数ショット学習},
year = {2018}
}
@inproceedings{Iwana2018,
abstract = {In this paper, we propose the use of local distance-based features determined by Dynamic Time Warping (DTW) for temporal Convolutional Neural Networks (CNN). Traditionally, DTW is used as a robust distance metric for time series patterns. However, this traditional use of DTW only utilizes the scalar distance metric and discards the local distances between the dynamically matched sequence elements. This paper proposes recovering these local distances, or DTW features, and utilizing them for the input of a CNN. We demonstrate that these features can provide additional information for the classification of isolated handwritten digits and characters. Furthermore, we demonstrate that the DTW features can be combined with the spatial coordinate features in multi-modal fusion networks to achieve state-of-the-art accuracy on the Unipen online handwritten character datasets.},
author = {Iwana, Brian Kenji and Mori, Minoru and Kimura, Akisato and Uchida, Seiichi},
booktitle = {International Conference on Frontiers in Handwriting Recognition (ICFHR)},
doi = {10.1109/ICFHR-2018.2018.00025},
isbn = {9781538658758},
issn = {21676453},
keywords = {Convolutional Neural Networks,Dynamic Time Warping,Multi modal fusion networks,Time series classification},
organization = {IEEE},
pages = {92--97},
title = {{Introducing Local Distance-Based Features to Temporal Convolutional Neural Networks}},
year = {2018}
}
@techreport{Hibino2017,
abstract = {This paper proposes a novel type of random forests called a denoising random forests that are robust against noises contained in test samples. Such noise-corrupted samples cause serious damage to the estimation performances of random forests, since unexpected child nodes are often selected and the leaf nodes that the input sample reaches are sometimes far from those for a clean sample. Our main idea for tackling this problem originates from a binary indicator vector that encodes a traversal path of a sample in the forest. Our proposed method effectively employs this vector by introducing denoising autoencoders into random forests. A denoising autoencoder can be trained with indicator vectors produced from clean and noisy input samples, and non-leaf nodes where incorrect decisions are made can be identified by comparing the input and output of the trained denoising autoencoder. Multiple traversal paths with respect to the nodes with incorrect decisions caused by the noises can then be considered for the estimation.},
author = {Hibino, Masaya and Kimura, Akisato and Yamashita, Takayoshi and Yamauchi, Yuji and Fujiyoshi, Hironobu},
booktitle = {arXiv preprint arXiv:1710.11004},
title = {{Denoising random forests}},
url = {https://arxiv.org/abs/1710.11004v1},
year = {2017}
}
@techreport{2017,
author = {中澤, 篤志 and 山崎, 俊彦 and 松下, 康之 and 安倍, 満 and 舩冨, 卓哉 and 木村, 昭悟 and 内田, 誠一 and 前田, 英作},
journal = {電子情報通信学会技術研究報告 PRMU},
number = {362},
pages = {41--43},
publisher = {電子情報通信学会},
title = {{PRMU 応用研究におけるオープンアイデア: PRMU 第二期グランドチャレンジ}},
volume = {117},
year = {2017}
}
@inproceedings{Kimura2017,
abstract = {Supernovae Type-Ia (SNeIa) play a significant role in exploring the history of the expansion of the Universe, since they are the best-known standard candles with which we can accurately measure the distance to the objects. Finding large samples of SNeIa and investigating their detailed characteristics have become an important issue in cosmology and astronomy. Existing methods relied on a photometric approach that first measures the luminance of supernova candidates precisely and then fits the results to a parametric function of temporal changes in luminance. However, it inevitably requires multi-epoch observations and complex luminance measurements. In this work, we present a novel method for classifying SNeIa simply from single-epoch observation images without any complex measurements, by effectively integrating the state-of-the-art computer vision methodology into the standard photometric approach. Our method first builds a convolutional neural network for estimating the luminance of supernovae from telescope images, and then constructs another neural network for the classification, where the estimated luminance and observation dates are used as features for classification. Both of the neural networks are integrated into a single deep neural network to classify SNeIa directly from observation images. Experimental results show the effectiveness of the proposed method and reveal classification performance comparable to existing photometric methods with multi-epoch observations.},
author = {Kimura, Akisato and Takahashi, Ichiro and Tanaka, Masaomi and Yasuda, Naoki and Ueda, Naonori and Yoshida, Naoki},
booktitle = {International Conference on Distributed Computing Systems Workshops (ICDCSW)},
doi = {10.1109/ICDCSW.2017.47},
isbn = {9781538632925},
keywords = {Supernova,convolutional neural network,deep learning,image classification,redshift},
pages = {1--8},
title = {{Single-Epoch Supernova Classification with Deep Convolutional Neural Networks}},
year = {2017}
}
@inproceedings{Hirose2017,
abstract = {n this paper, we explore the challenge of automatically generating attractive news headlines for social media, which can be good introductions to make news articles go viral. To this end, we propose a novel method for identifying key sentences that are useful for generating viral news headlines from a given news article. This problem can be formulated as supervised sequence labelling that employs the most popular microblog post mentioning the news article as supervised information, and a recurrent neural network (RNN) can be used for this purpose. However, weshow that a na{\"{i}}ve implementation of this approach does not work well, due to noises contained in both microblog messages as the ground-truth headlines and news articles, and data cleansing and organizing for news articles and ground-truth headlines are rather criticalfor improving the performance of sequence labelling. We then propose a method for organizing a dataset for training accurate models for supervised sequence labeling. The experimental results demonstrate that our proposed method greatly improve the accuracy of key sentence identification.},
author = {Hirose, Yuka and Kimura, Akisato and Fujishiro, Hiroyuki},
booktitle = {Computational + Journalism Symposium (C+J)},
title = {{Cleansing, organizing and training: Two guidelines for generating attractive news headlines for social media}},
url = {https://northwestern.box.com/s/212p7bouuk3vyg125lbuft0laqd2k0uv},
year = {2017}
}
@incollection{2017a,
author = {木村, 昭悟},
booktitle = {人工知能大辞典},
editor = {松原, 仁 and 本村, 陽一 and 栗原, 聡 and 長尾, 確 and 橋田, 浩一 and 丸山, 文宏},
isbn = {978-4-320-12420-2},
publisher = {共立出版},
title = {{画像メディアとSNS}},
url = {https://www.kyoritsu-pub.co.jp/ai/index.html},
year = {2017}
}
@inproceedings{Ishiguro2016,
abstract = {We propose a probabilistic model for non-exhaustive and overlapping (NEO) bi-clustering. Our goal is to extract a few sub-matrices from the given data matrix, where entries of a sub-matrix are characterized by a specific distribution or parameters. Existing NEO bi-clustering methods typically require the number of sub-matrices to be extracted, which is essentially difficult to fix a priori. In this paper, we extend the plaid model, known as one of the best NEO bi-clustering algorithms, to allow infinite bi-clustering; NEO bi-clustering without specifying the number of sub-matrices. Our model can represent infinite sub-matrices formally. We develop a MCMC inference without the finite truncation, which potentially addresses all possible numbers of sub-matrices. Experiments quantitatively and qualitatively verify the usefulness of the proposed model. The results reveal that our model can offer more precise and in-depth analysis of sub-matrices.},
author = {Ishiguro, Katsuhiko and Sato, Issei and Nakano, Masahito and Kimura, Akisato and Ueda, Naonori},
booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
isbn = {9781577357605},
keywords = {Bayesian Nonparametrics,NEO bi-clusteirng,bi-clustering,clustering,infinite bi-clustering},
title = {{Infinite plaid models for infinite bi-clustering}},
url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewPaper/11786},
year = {2016}
}
@techreport{2016,
author = {村田, 隆英 and 木村, 昭悟 and 牛久, 祥孝 and 山下, 隆義 and 山内, 悠嗣 and 藤吉, 弘亘},
journal = {電子情報通信学会技術研究報告 PRMU},
number = {516},
pages = {191--196},
publisher = {電子情報通信学会},
title = {{教師あり学習の導入による Mondrian Forests の効率化}},
volume = {115},
year = {2016}
}
@techreport{2016a,
author = {中野, 允裕 and 渡邊, 千紘 and 木村, 昭悟 and 平松, 薫},
journal = {電子情報通信学会技術研究報告 IBISML},
number = {300},
pages = {163--170},
publisher = {電子情報通信学会},
title = {組み合わせ論的拘束を持つ確率過程の構成},
volume = {116},
year = {2016}
}
@article{2016b,
abstract = {本論文では，MapReduceの枠組を用いて大規模データからrandom forestsを学習する新しい手法を提案する．Random forestsは，多数の決定木によって構成され，かつそれぞれの決定木を独立に学習することができるため，並列分散処理に非常に適した機械学習手法である．しかし，random forestsの学習をナイーブに並列分散化すると，それぞれの決定木を学習するために利用可能な学習データが少量となるため，しばしば過学習を引き起こす．本論文で提案する手法は，この過学習の問題を，以下の三つの要素を導入することで解決する．(1)全てのワーカノードで共通にもつrandom forestsである共有RFを導入する．(2)各ワーカノードのMap処理で共変量シフト適応に基づく転移学習を利用することにより，それぞれのワーカノードが保持する学習データに共有RFを適応させ，高い分類性能を獲得する．(3)転移学習によって得られたrandom forestsをマスタノードに集約するreduce処理で，分類性能の向上に寄与しない決定木を削除することにより，分類性能を大幅に落とすことなく，分類時の計算コストを削減する．実験により，提案手法が分類性能を犠牲にすることなく高速な学習を実現できることを示す．},
author = {若山, 涼至 and 村田, 隆英 and 木村, 昭悟 and 山下, 隆義 and 山内, 悠嗣 and 藤吉, 弘亘},
journal = {電子情報通信学会論文誌},
keywords = {MapReduce,Random forests,並列分散処理,転移学習},
number = {8},
pages = {737--746},
title = {共変量シフト適応に基づくrandom forestsの並列分散学習},
url = {https://search.ieice.org/bin/summary.php?id=j99-d{\_}8{\_}737{\&}category=D{\&}lang=J{\&}year=2016{\&}abst=},
volume = {99-D},
year = {2016}
}
@article{2016c,
abstract = {SNSの隆盛によりニュースを取り巻く環境は大きく変化している．新聞やテレビから一方的に配信される記事を受け取るのではなく，膨大な情報で溢れるSNS上から関心のある記事を選択して購読する新たなニュースの読まれ方が生まれている．この変化により，ニュースメディアはSNS上で記事を読者に対して効果的にアピールする必要に迫られている．その一方で，刺激的な言葉を用いてむやみに拡散させるのではなく，記事を正確に説明し，その内容に興味をもつ読者に記事を届ける必要がある．本研究では，ニュース配信者がニュース消費者に適切なニュース記事を提供するための一手段として，ニュース記事を的確に説明する説明文が，SNS上でより多くの読者に読まれるために備えるべき性質を特定することを目指す．この目標に向け，本論文ではまず記者と編集者を対象としたヒアリング調査と，ニュースサイトがSNSに投稿している説明文の調査を行った．これらの調査を分析することで明らかになった，説明文がもつべき性質を利用することで，与えられたニュース記事をSNS上で紹介する説明文を幾つかの候補の中から自動的に選択する手法を提案する．},
author = {興梠, 紗和 and 木村, 昭悟 and 藤代, 裕之 and 西川, 仁},
journal = {電子情報通信学会論文誌},
keywords = {SNS,ニュース,ヒアリング調査,ランキング学習},
number = {4},
pages = {403--414},
title = {{SNS上で拡散するwebニュース説明文の調査と自動選択}},
url = {https://search.ieice.org/bin/summary.php?id=j99-d{\_}4{\_}403{\&}category=D{\&}lang=J{\&}year=2016{\&}abst=},
volume = {99-D},
year = {2016}
}
@inproceedings{Nagayama2016,
abstract = {A huge number of news artiles are distributed on soial media, and news onsumers an aess those artiles at any time from hand-held devies. This means that news providers are under pressure to nd ways of attrating the interest of news onsumers. One key fator that has a great impat on the attrativeness of a news artile is its headline as a way of guiding news onsumers to news artiles. This researh explores the hallenge of automatially generating attrative news headlines for soial media, and to this end we fous on the problem of identifying key sentenes that are useful for generating viral news headlines from a given news artile. We show that this problem an be formulated as supervised sequene labeling that utilizes user ativity on soial media as supervised information, and we propose a neural network model for this purpose. Investigations with our orpus onsisting of miroblog posts and news artiles demonstrate that lead sentenes believed to be the most suitable for news summaries do not neessarily ontribute to inreased virality whereas our proposed method an aurately identify key sentenes.},
author = {Nagayama, Kota and Kimura, Akisato and Fujishiro, Hiroyuki},
booktitle = {Computational + Journalism Symposium (C+J)},
title = {{Make it go viral - Generating attractive headlines for distributing news articles on social media}},
url = {http://journalism.stanford.edu/cj2016/files/Make it go viral.pdf},
year = {2016}
}
@incollection{2016d,
author = {木村, 昭悟},
journal = {日本光学会誌},
number = {1},
pages = {22--28},
title = {映像の知覚的顕著性に基づく視覚的注意の予測},
volume = {45},
year = {2016}
}
@inproceedings{Nakajima2015,
abstract = {Human visual attention can be modulated not only by visual stimuli but also by ones from other modalities such as audition. Hence, incorporating auditory information into a human visual attention model would be a key issue for building more sophisticated models. However, the way of integrating multiple pieces of information arising from audio-visual domains still remains a challenging problem. This paper proposes a novel computational model of human visual attention driven by auditory cues. Founded on the Bayesian surprise model that is considered to be promising in the literature, our model uses surprising auditory events to serve as a clue for selecting synchronized visual features and then emphasizes the selected features to form the final surprise map. Our approach to audio-visual integration focuses on using effective visual features alone but not all available features for simulating visual attention with the help of auditory information. Experiments using several video clips show that our proposed model can better simulate eye movements of human subjects than other existing models in spite that our model uses a smaller number of visual features.},
author = {Nakajima, Jiro and Kimura, Akisato and Sugimoto, Akihiro and Kashino, Kunio},
booktitle = {International Conference on Multimedia Modeling (MMM)},
doi = {10.1007/978-3-319-14442-9_7},
isbn = {9783319144412},
issn = {16113349},
keywords = {Auditory cues,Bayesian surprise,Feature selection,Synchronization,Visual attention},
pages = {74--86},
title = {{Visual Attention Driven by Auditory Cues}},
url = {http://link.springer.com/10.1007/978-3-319-14442-9{\_}7},
volume = {8936},
year = {2015}
}
@inproceedings{Fujiki2015,
abstract = {This paper provides a geometrical aspect of Fisher's linear discriminant analysis (FLDA), which has been widely used owing to its simple formulation and low computational costs. Our approach is based on a new framework of pattern recognition that can be modelded by a communication of class information. This model is quite different from a commonly used framework of pattern recognition as a mapping from the set of patterns to the set of classes. In the new framework, patterns can be regarded as class information with redundant encoding. We show that the geometry of two class FLDA can be described via communication theory of noisy channel.},
author = {Fujiki, Jun and Tanaka, Masaru and Sakano, Hitoshi and Kimura, Akisato},
booktitle = {IAPR International Conference on Machine Vision Applications (MVA)},
doi = {10.1109/MVA.2015.7153198},
isbn = {978-4-9011-2214-6},
month = {may},
pages = {333--336},
publisher = {IEEE},
title = {{Geometric interpretation of Fisher's linear discriminant analysis through communication theory}},
url = {http://ieeexplore.ieee.org/document/7153198/},
year = {2015}
}
@incollection{2015,
abstract = {ソーシャルネットワーキングサービス（SNS）で取り扱われるメディアは，テキストからなるマイクロブログ形式から，画像・映像・音楽等のマルチメディアコンテンツを含む形式へ変遷し，スマートフォンの普及によりその傾向は急速に強まっている．すなわち，SNSとスマートフォンの普及により，画像に強い興味を持たないユーザ層が気軽に画像をアップロードするようになり，その量は爆発的に増加している．これらSNS上の画像・映像コンテンツは，マイクロブログのテキスト，位置情報，時刻，ユーザ間の関係性など，画像や映像の内容を知る上で非常に有用な付加情報を数多く含んでいる．本解説では，日々大量に生成され，様々な付加情報を持つ，SNS上の画像をコーパスとして用いる画像認識・理解の近年の取り組みについて，概観する．},
author = {木村, 昭悟},
journal = {情報処理},
number = {7},
pages = {646--651},
title = {ソーシャルネットワークが変える画像の認識・理解},
url = {https://ipsj.ixsq.nii.ac.jp/ej/?action=pages{\_}view{\_}main{\&}active{\_}action=repository{\_}view{\_}main{\_}item{\_}detail{\&}item{\_}id=142371{\&}item{\_}no=1{\&}page{\_}id=13{\&}block{\_}id=8},
volume = {56},
year = {2015}
}
@techreport{2015a,
author = {石黒, 勝彦 and 木村, 昭悟},
journal = {電子情報通信学会技術研究報告 PRMU},
number = {388},
pages = {13--24},
publisher = {電子情報通信学会},
title = {パターン認識研究者のためのトピックモデリング概観},
url = {https://www.ieice.org/ken/paper/20151221PbEz/},
volume = {115},
year = {2015}
}
@inproceedings{Kourogi2015,
abstract = {In the past, leading newspaper companies and broadcasters were the sole distributors of news articles, and thus news consumers simply received news articles from those outlets at regular intervals. However, the growth of social media and smart devices led to a considerable change in this traditional relationship between news providers and consumers. Hundreds of thousands of news articles are now distributed on social media, and consumers can access those articles at any time via smart devices. This has meant that news providers are under pressure to find ways of engaging the attention of consumers. This paper provides a novel solution to this problem by identifying attractive headlines as a gateway to news articles. We first perform one of the first investigations of news headlines on a major viral medium. Using our investigation as a basis, we also propose a learning-to-rank method that suggests promising news headlines. Our experiments with 2,000 news articles demonstrate that our proposed method can accurately identify attractive news headlines from the candidates and reveals several promising factors of making news articles go viral.},
author = {Kourogi, Sawa and Kimura, Akisato and Nishikawa, Hitoshi and Fujishiro, Hiroyuki},
booktitle = {ACM International Conference on Information and Knowledge Management (CIKM)},
doi = {10.1145/2806416.2806631},
isbn = {9781450337946},
keywords = {Learning to rank,News headlines,Social media,Virality},
pages = {1859--1862},
title = {{Identifying attractive news headlines for social media}},
url = {https://dl.acm.org/citation.cfm?id=2806631},
year = {2015}
}
@inproceedings{Wakayama2015,
abstract = {This paper proposes a novel method for training random forests with big data on MapReduce clusters. Random forests are well suited for parallel distributed systems, since they are composed of multiple decision trees and every decision tree can be independently trained by ensemble learning methods. However, naive implementation of random forests on distributed systems easily overfits the training data, yielding poor classification performances. This is because each cluster node can have access to only a small fraction of the training data. The proposed method tackles this problem by introducing the following three steps. (1) "Shared forests" are built in advance on the master node and shared with all the cluster nodes. (2) With the help of transfer learning, the shared forests are adapted to the training data placed on each cluster node. (3) The adapted forests on every cluster node are returned to the master node, and irrelevant trees yielding poor classification performances are removed to form the final forests. Experimental results show that our proposed method for MapReduce clusters can quickly learn random forests without any sacrifice of classification performance.},
author = {Wakayama, Ryoji and Murata, Ryuei and Kimura, Akisato and Yamashita, Takayoshi and Yamauchi, Yuji and Fujiyoshi, Hironobu},
booktitle = {Proc. IAPR Asian Conference on Pattern Recognition (ACPR)},
doi = {10.1109/ACPR.2015.7486509},
isbn = {9781479961009},
issn = {2327-0985},
keywords = {Decision trees,Distributed forests,MapReduce,ensemble learning methods},
month = {nov},
pages = {276--280},
title = {{Distributed forests for MapReduce-based machine learning}},
year = {2015}
}
@article{2015b,
abstract = {本論文では，画像を扱うソーシャルキュレーションサービスの1つであるPinterestの画像データから，共通するコンテクストを持つ画像群を自動的に発見する手法を提案する．ソーシャルキュレーションは，日本語では一般に「まとめサイト」とも呼ばれ，キュレーターと呼ばれる人間が既存コンテンツを人手で収集・選択した結果を編集コンテンツ群として共有する仕組みである．その結果として得られた編集コンテンツ群は，通常のSNS上のコンテンツとは異なり，キュレーターにとって不要なコンテンツが除去され，キュレーターの意図や意見を反映した一貫した指針に基づいて生成されている．このことから，編集コンテンツ群を構成するコンテンツは，共通のコンテクストを保持していることが期待される．本論文では，このソーシャルキュレーションのプロセスに着目することで，自然言語との直接的な対応付けが必ずしも容易であるとは限らない概念やコンテクストなどを共有する画像群を，非常にシンプルな手法で大量に発見できることを示す．さらに本論文では，発見した画像群を画像認識・検索のための類似性を自動的に獲得するための重要なステップとして，コンテクストの共通性を考慮した画像特徴量の低次元埋め込み手法を提案する．この手法を利用することで，類似するコンテクストを持つと思われる画像が類似する低次元特徴量を持つような埋め込みを実現するとともに，画像分類のタスクで同様の機能を実現する従来手法と比較して高い分類性能を実現できることを実験的に示す．},
author = {木村, 昭悟 and 石黒, 勝彦 and Alvarez, Alejandro Marcos and 山田, 誠 and 片岡, 香織 and 村崎, 和彦},
journal = {情報処理学会論文誌 数理モデルと応用},
number = {3},
pages = {10--25},
title = {ソーシャルキュレーションデータを用いた画像コンテクストマイニング},
url = {http://id.nii.ac.jp/1001/00146299/},
volume = {8},
year = {2015}
}
@book{2015c,
abstract = {すべてをつなげるソーシャルメディアをどのように使いこなすのか――歴史や技術、関連する事象、今後の課題を学び、人や社会とのつながりを再設計するメディア・リテラシーの獲得に必要な視点を提示する。新たなメディア環境を生きていくための教科書。 2015年の刊行以来、5刷を重ねた好評の『ソーシャルメディア論』の改訂版。 フェイクニュース、購入・視聴履歴や位置情報といったビッグデータ、AI、IoT、クラウドファンディング――ソーシャルメディアは人と情報のつながりを変え、社会を大きく変えようとしている。 しかし、学校や企業でソーシャルメディアを体系的に学ぶ機会は少ない。本書は、ソーシャルメディアの歴史や裏側を動かす技術、関連する法律をわかりやすく解説し、ソーシャルメディアの仕組みを理解できる教科書である。すべてをつなげるソーシャルメディアをどのように使いこなすのか、人や社会とのつながりを再設計する新たなメディア・リテラシー獲得のための視点を提示する。 改訂に際しては、特にアメリカ大統領選挙で明らかになったフェイクニュースがもたらす危険性について各章をアップデートして、理解が進むように工夫した。「権利」「メディア」を「コンテンツ」「地域」に変更し、二次創作や関係人口といったトピックを組み込んだ。},
author = {藤代, 裕之 and 一戸, 信哉 and 山口, 浩 and 五十嵐, 悠紀 and 生貝, 直人 and 伊藤, 儀雄 and 小笠原, 伸 and 木村, 昭悟 and 工藤, 郁子 and 小林, 啓倫 and 新志, 有裕 and 田中, 輝美 and 西田, 亮介 and 松本, 淳},
isbn = {978-4-7872-3449-0},
publisher = {青弓社},
title = {ソーシャルメディア論： つながりを再設計する},
url = {https://www.seikyusha.co.jp/bd/isbn/9784787234490/},
year = {2015}
}
@inproceedings{Nakano2014,
abstract = {This paper proposes a novel stochastic process that represents the arbitrary rectangular partitioning of an infinite-dimensional matrix as the conditional projective limit. Rectangular partitioning is used in relational data analysis, and is classified into three types: regular grid, hierarchical, and arbitrary. Conventionally, a variety of probabilistic models have been advanced for the first two, including the product of Chinese restaurant processes and the Mondrian process. However, existing models for arbitrary partitioning are too complicated to permit the analysis of the statistical behaviors of models, which places very severe capability limits on relational data analysis. In this paper, we propose a new probabilistic model of arbitrary partitioning called the rectangular tiling process (RTP). Our model has a sound mathematical base in projective systems and infinite extension of conditional probabilities, and is capable of representing partitions of infinite elements as found in ordinary Bayesian nonparametric models.},
author = {Nakano, Masahito and Ishiguro, Katsuhiko and Kimura, Akisato and Yamada, Takeshi and Ueda, Naonori},
booktitle = {International Conference on Machine Learning (ICML)},
isbn = {9781634393973},
pages = {361--369},
title = {{Rectangular tiling process}},
url = {http://proceedings.mlr.press/v32/nakano14.html},
volume = {2},
year = {2014}
}
@techreport{2014,
author = {木村, 昭悟 and 柏野, 邦夫 and 平松, 薫 and 川西, 隆仁},
journal = {電子情報通信学会技術研究報告 PRMU},
number = {230},
pages = {39--44},
publisher = {一般社団法人電子情報通信学会},
title = {クラウドプレイリストネットワークを用いた音楽ストリーミング再生リストの自動生成 (パターン認識・メディア理解)},
volume = {114},
year = {2014}
}
@techreport{2014a,
author = {中野, 允裕 and 石黒, 勝彦 and 木村, 昭悟 and 山田, 武士 and 上田, 修功},
journal = {電子情報通信学会技術研究報告 IBISML},
number = {306},
pages = {313--320},
publisher = {一般社団法人電子情報通信学会},
title = {無限交換長方形分割},
volume = {114},
year = {2014}
}
@techreport{2014b,
author = {田良島, 周平 and 三上, 弾 and 木村, 昭悟},
journal = {情報処理学会 研究報告 AVM},
number = {9},
pages = {1--3},
title = {{ACM Multimedia 2013 参加報告と関連研究動向}},
volume = {2014},
year = {2014}
}
@incollection{2014c,
author = {生貝, 直人 and 一戸, 信哉 and 木村, 昭悟},
journal = {情報ネットワーク・ローレビュー},
number = {1},
pages = {200--223},
publisher = {商事法務},
title = {オープンプライバシーの諸問題: ソーシャルメディア社会における情報流通と制度設計 中間報告},
volume = {13},
year = {2014}
}
@article{Kimura2014pii,
abstract = {The major interest of the current social network service (SNS) developers and users are rapidly shifting from conventional text-based (micro)blogs such as Twitter and Facebook to multimedia contents such as Flickr, Snapchat, MySpace and Tumblr. However, the ability to analyze and exploit unorganized multimedia contents on those services still remain inadequate, even with state-of-the-art media processing and machine learning techniques. This paper focuses on another emerging trend called social curation, a human-in-the-loop alternative to automatic algorithms for social media analysis. Social curation can be defined as a spontaneous human process of remixing social media content for the purpose of further consumption. What characterize social curation are definitely the manual efforts involved in organizing a collection of social media contents, which indicates that socially curated content has a potential as a promising information source against automatic summaries generated by algorithms. Curated contents would also provide latent perspectives and contexts that are not explicitly presented in the original resources. Following this trend, this paper presents recent developments and growth of social curation services, and reviews several research trials for cross-media analysis and mining from socially curated contents. {\textcopyright} 2014 National Institute of Informatics.},
author = {Kimura, Akisato},
doi = {10.2201/NiiPi.2014.11.4},
issn = {13498606},
journal = {Progress in Informatics},
keywords = {Content curation,Cross-media analysis,Cross-media mining,Human computation,Social media},
number = {1},
pages = {19--30},
title = {{Large-scale cross-media analysis and mining from socially curated contents}},
volume = {11},
year = {2014}
}
@article{ieiceTrans_autotogetter,
abstract = {Social media such as microblogs have become so pervasive such that it is now possible to use them as sensors for real-world events and memes. While much recent research has focused on developing automatic methods for filtering and summarizing these data streams, we explore a different trend called social curation. In contrast to automatic methods, social curation is characterized as a human-in-the-loop and sometimes crowd-sourced mechanism for exploiting social media as sensors. Although social curation web services like Togetter, Naver Matome and Storify are gaining popularity, little academic research has studied the phenomenon. In this paper, our goal is to investigate the phenomenon and potential of this new field of social curation. First, we perform an in-depth analysis of a large corpus of curated microblog data. We seek to understand why and how people participate in this laborious curation process. We then explore new ways in which information retrieval and machine learning technologies can be used to assist curators. In particular, we propose a novel method based on a learning-to-rank framework that increases the curator's productivity and breadth of perspective by suggesting which novel microblogs should be added to the curated content. Copyright {\textcopyright} 2014 The Institute of Electronics, Information and Communication Engineers.},
author = {Kimura, Akisato and Duh, Kevin and Hirao, Tsutomu and Ishiguro, Katsuhiko and Iwata, Tomoharu and {Au Yeung}, Albert},
doi = {10.1587/transinf.E97.D.1557},
issn = {17451361},
journal = {IEICE Transactions on Information and Systems},
keywords = {Learning to rank,Microblogging,Social curation},
number = {6},
pages = {1557--1566},
title = {{Creating stories from socially curated microblog messages}},
volume = {E97-D},
year = {2014}
}
@article{2014d,
abstract = {行列分解には，観測行列に含まれる零要素の割合が大きくなるにつれて低ランク近似の汎化性能が低下する問題がある．本稿では，この問題を解決するための統計的機械学習アプローチとして複合非負値行列因子分解（Non-negative Multiple Matrix Factorization: NM2F）を提案する．NM2F は，観測行列と2つの補助行列の間に共通の潜在構造を仮定し，これらの行列を同時に分解する．本稿では，NM2F を非負値行列因子分解（Non-negative Matrix Factorization: NMF）の一般化として定式化し，補助関数法により一般化KLダイバージェンスを用いた場合のパラメータ推定法を示す．さらにNM2F は，ブロック未定義領域ありNMFとポアソン分布を用いた確率的生成モデルと等価であることを示す．人工データと実データを用いた実験から，NM2F と既存手法の汎化性能を比較し，NM2F の定量的な優位性を示す．また，実データを用いた実験では，NM2F が複数の行列から多角的な基底を抽出する定性的な利点を示す．},
author = {竹内, 孝 and 石黒, 勝彦 and 木村, 昭悟 and 澤田, 宏},
journal = {情報処理学会論文誌 数理モデルと応用},
number = {1},
pages = {71--83},
title = {非負制約下における複合行列分解とそのソーシャルメディア解析への応用},
volume = {7},
year = {2014}
}
@book{2014e,
abstract = {機械学習とは，コンピュータに学習能力を持たせるための方法論を研究する学問の名称であり，もともとは人工知能分野の一部として研究されていた。その後，機械学習は統計学と密接な関わりを持つようになり，「統計的学習」として独自の発展の道を歩み始めた。そして，1990年代から現在に至るまでの計算機やインターネットの爆発的な普及と相まって統計的学習の技術は目覚ましい発展を遂げ，いまや情報検索，オンラインショッピングなど，われわれの日常生活とは切り離すことのできない情報通信技術の根幹を支える重要な要素技術の一つとなった。 本書は，このような発展著しい統計的学習分野の世界的に著名な教科書である“The Elements of Statistical Learning” の全訳である。回帰や分類などの教師あり学習の入門的な話題から，ニューラルネットワーク，サポートベクトルマシンなどのより洗練された学習器，ブースティングやアンサンブル学習などの学習手法の高度化技術，さらにはグラフィカルモデルや高次元学習問題に対するスパース学習法などの最新の話題までを幅広く網羅しており，計算機科学などの情報技術を専門とする大学生・大学院生，および，機械学習技術を基礎科学や産業に応用しようとしている大学院生・研究者・技術者にとって最適な教科書である。},
author = {井尻, 善久 and 井手, 剛 and 岩田, 具治 and 金森, 敬文 and 兼村, 厚範 and 烏山, 昌幸 and 河原, 吉伸 and 木村, 昭悟 and 小西, 嘉典 and 酒井, 智弥 and 鈴木, 大慈 and 竹内, 一郎 and 玉木, 徹 and 出口, 大輔 and 冨岡, 亮太 and 波部, 斉 and 前田, 新一 and 持橋, 大地 and 山田, 誠},
editor = {杉山, 将 and 井手, 剛 and 神嶌, 敏弘 and 栗田, 多喜夫 and 前田, 英作},
isbn = {978-4-320-12362-5},
publisher = {共立出版},
title = {統計的学習の基礎},
url = {https://www.kyoritsu-pub.co.jp/bookdetail/9784320123625},
year = {2014}
}
@incollection{2014f,
author = {木村, 昭悟},
booktitle = {文藝春秋オピニオン 2014年の論点100},
publisher = {文藝春秋社},
title = {論点(16) 消費税増税と国内経済： 2014年期待の新産業： グーグルグラスとは何か},
url = {https://www.bunshun.co.jp/mag/extra/ronten/ronten2014.htm},
year = {2014}
}
@incollection{2014g,
author = {木村, 昭悟 and 米谷, 竜 and 平山, 高嗣},
journal = {電子情報通信学会 情報・システムソサイエティ誌},
number = {2},
pages = {17},
title = {人間の視覚的注意の計算モデル - 人の視聴覚情報処理とパターン認識・メディア理解との接点},
url = {https://www.ieice.org/iss/jpn/Publications/society{\_}mag/pdf/Vol19No2.pdf},
volume = {19},
year = {2014}
}
@incollection{2014h,
author = {木村, 昭悟 and 数原, 良彦 and 高橋, 寛幸 and 横山, 達彦},
journal = {画像ラボ},
number = {3},
pages = {24--32},
title = {画像検索でのユーザ行動を利用した大規模画像アノテーション},
url = {https://www.fujisan.co.jp/product/1281679689/b/1051075/},
volume = {25},
year = {2014}
}
@article{2013,
abstract = {本論文では,画像検索サーバのログを利用することで,画像そのものから得られる特徴量等の情報を一切用いずに,web上の画像とそれに関連するテキストタグを全自動・大量かつ高精度に収集し,画像マルチラベル分類のための大規模データセットを構築する方法を提案する.特に,画像検索のランキング学習などで広く用いられる画像のクリックログだけではなく,クエリ投入やページ遷移など検索サーバへのアクセスログから得られる様々な情報を有効活用する.これらの情報を併用することにより,クリックログのみからでは得られなかったクリックの重要性やユーザ行動の意図などが一定程度推定可能となり,画像に対するテキストタグのアノテーションを高精度に実現できる.実データを用いた実験によって,提案手法のアノテーション精度を評価し,有効性を確認した.},
author = {木村, 昭悟 and 数原, 良彦 and 高橋, 寛幸 and 横山, 達彦},
issn = {18804535},
journal = {電子情報通信学会論文誌},
keywords = {access log,image annotation,image retrieval,user activity,大規模データセット,検索ログ,画像アノテーション,画像検索},
mendeley-tags = {access log,image annotation,image retrieval,user activity},
month = {aug},
number = {8},
pages = {1711--1723},
publisher = {一般社団法人電子情報通信学会},
title = {画像検索でのユーザ行動を利用した大規模画像アノテーション},
url = {http://ci.nii.ac.jp/naid/110009634943/},
volume = {96},
year = {2013}
}
@inproceedings{Takeuchi2013,
abstract = {Non-negative Matrix Factorization (NMF) is a traditional unsupervised machine learning technique for decomposing a matrix into a set of bases and coefficients under the non-negative constraint. NMF with sparse constraints is also known for extracting reasonable components from noisy data. However, NMF tends to give undesired results in the case of highly sparse data, because the information included in the data is insufficient to decompose. Our key idea is that we can ease this problem if complementary data are available that we could integrate into the estimation of the bases and coefficients. In this paper, we propose a novel matrix factorization method called Non-negative Multiple Matrix Factorization (NMMF), which utilizes complementary data as auxiliary matrices that share the row or column indices of the target matrix. The data sparse- ness is improved by decomposing the target and auxiliary matrices simultaneously, since auxiliary matrices provide information about the bases and coefficients. We formulate NMMF as a generalization of NMF, and then present a parameter estimation procedure derived from the multiplicative up- date rule. We examined NMMF in both synthetic and real data experiments. The effect of the auxiliary matrices appeared in the improved NMMF performance. We also confirmed that the bases that NMMF obtained from the real data were intuitive and reasonable thanks to the non-negative constraint.},
author = {Takeuchi, Koh and Ishiguro, Katsuhiko and Kimura, Akisato and Sawada, Hiroshi},
booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
keywords = {Non-negative Matrix Factorization,Social Curration},
pages = {1713--1720},
title = {{Non-negative multiple matrix factorization}},
url = {https://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/viewPaper/6762},
year = {2013}
}
@article{Kimura2013,
abstract = {Canonical correlation analysis (CCA) is a powerful tool for analyzing multi-dimensional paired data. However, CCA tends to perform poorly when the number of paired samples is limited, which is often the case in practice. To cope with this problem, we propose a semi-supervised variant of CCA named SemiCCA that allows us to incorporate additional unpaired samples for mitigating overfitting. Advantages of the proposed method over previously proposed methods are its computational efficiency and intuitive operationality: it smoothly bridges the generalized eigenvalue problems of CCA and principal component analysis (PCA), and thus its solution can be computed efficiently just by solving a single eigenvalue problem as the original CCA. {\textcopyright} 2013 Information Processing Society of Japan.},
author = {Kimura, Akisato and Sugiyama, Masashi and Nakano, Takuho and Kameoka, Hirokazu and Sakano, Hitoshi and Maeda, Eisaku and Ishiguro, Katsuhiko},
doi = {10.2197/ipsjtrans.6.37},
issn = {1882-6660},
journal = {IPSJ Transactions on Mathematical Modeling and its Applications (TOM)},
keywords = {Canonical correlation analysis,Generalized eigenproblem,Multi-label prediction,Principal component analysis,Semi-supervised learning},
number = {1},
pages = {37--44},
title = {{SemiCCA: Efficient Semi-supervised Learning of Canonical Correlations}},
url = {http://jlc.jst.go.jp/DN/JST.JSTAGE/ipsjtrans/6.37?lang=en{\&}from=CrossRef{\&}type=abstract},
volume = {6},
year = {2013}
}
@techreport{2013a,
author = {片岡, 香織 and 木村, 昭悟 and 村崎, 和彦 and 数藤, 恭子 and 谷口, 行信},
journal = {電子情報通信学会技術研究報告: 信学技報},
number = {441},
pages = {19--24},
publisher = {一般社団法人電子情報通信学会},
title = {{SNS を利用したトピックモデルによる画像へのユーザ嗜好陛の解析}},
volume = {112},
year = {2013}
}
@article{Kimura2013a,
abstract = {It is well known that dimensionality reduction based on multivariate analysis methods and their kernelized extensions can be formulated as generalized eigenvalue problems of scatter matrices, Gram matrices or their augmented matrices. This paper provides a generic and theoretical framework of multivariate analysis introducing a new expression for scatter matrices and Gram matrices, called Generalized Pairwise Expression (GPE). This expression is quite compact but highly powerful. The framework includes not only (1) the traditional multivariate analysis methods but also (2) several regularization techniques, (3) localization techniques, (4) clustering methods based on generalized eigenvalue problems, and (5) their semi-supervised extensions. This paper also presents a methodology for designing a desired multivariate analysis method from the proposed framework. The methodology is quite simple: adopting the above mentioned special cases as templates, and generating a new method by combining these templates appropriately. Through this methodology, we can freely design various tailor-made methods for specific purposes or domains. {\textcopyright} 2013 Information Processing Society of Japan.},
author = {Kimura, Akisato and Sugiyama, Masashi and Sakano, Hitoshi and Kameoka, Hirokazu},
doi = {10.2197/ipsjtrans.6.45},
issn = {18826660},
journal = {IPSJ Transactions on Mathematical Modeling and its Applications (TOM)},
keywords = {Clustering,Dimensionality reduction,Generalized eigenvalue problem,Kernel method,Multivariate analysis,Pairwise expression,Regularization,Semi-supervised learning},
number = {1},
pages = {136--145},
title = {{Designing various multivariate analysis at will via generalized pairwise expression}},
volume = {6},
year = {2013}
}
@inproceedings{MarcosAlvarez2013,
abstract = {This paper proposes a simple yet effective anomaly detection method for multi-view data. The proposed approach detects anomalies by comparing the neighborhoods in different views. Specifically, clustering is performed separately in the different views and affinity vectors are derived for each object from the clustering results. Then, the anomalies are detected by comparing affinity vectors in the multiple views. An advantage of the proposed method over existing methods is that the tuning parameters can be determined effectively from the given data. Through experiments on synthetic and benchmark datasets, we show that the proposed method outperforms existing methods. Copyright 2013 ACM.},
author = {{Marcos Alvarez}, Alejandro and Yamada, Makoto and Kimura, Akisato and Iwata, Tomoharu},
booktitle = {ACM International Conference on Information and Knowledge Management (CIKM)},
doi = {10.1145/2505515.2507840},
isbn = {9781450322638},
keywords = {Affinity propagation,Anomaly detection,Multi-view data},
organization = {ACM},
pages = {1545--1548},
title = {{Clustering-based anomaly detection in multi-view data}},
year = {2013}
}
@inproceedings{Kimura2013b,
abstract = {This paper proposes a novel method of discovering a set of image contents sharing a specific context (attributes or implicit meaning) with the help of image collections obtained from social curation platforms. Socially curated contents are promising to analyze various kinds of multimedia information, since they are manually filtered and organized based on specific individual preferences, interests or perspectives. Our proposed method fully exploits the process of social curation: (1) How image contents are manually grouped together by users, and (2) how image contents are distributed in the platform. Our method reveals the fact that image contents with a specific context are naturally grouped together and every image content includes really various contexts that cannot necessarily be verbalized by texts. Copyright {\textcopyright} 2013 ACM.},
author = {Kimura, Akisato and Ishiguro, Katsuhiko and Yamada, Makoto and {Marcos Alvarez}, Alejandro and Kataoka, Kaori and Murasaki, Kazuhiko and Alvarez, A.M. and Kataoka, Kaori and Murasaki, Kazuhiko},
booktitle = {ACM International Conference on Multimedia (ACMMM)},
doi = {10.1145/2502081.2502149},
isbn = {9781450324045},
keywords = {Classification,Contexts,Graph clustering,Social curation},
pages = {565--568},
publisher = {ACM},
title = {{Image context discovery from socially curated contents}},
url = {http://doi.acm.org/10.1145/2502081.2502149 http://dl.acm.org/citation.cfm?id=2502149},
year = {2013}
}
@inproceedings{MarcosAlvarez2013a,
abstract = {In this paper, we show how side information extracted from socially-curated data can be used within a dimensionality reduction method and to what extent this side information is beneficial to several tasks such as image classification, data visualization and image retrieval. The key idea is to incorporate side information of an image into a dimensionality reduction method. More specifically, we propose a dimensionality reduction method that can find an embedding transformation so that images with similar side information are close in the embedding space. We introduce three types of side information derived from user behavior. Through experiments on images from Pinterest, we show that incorporating socially-generated side information in a dimensionality reduction method benefits several image-related tasks such as image classification, data visualization and image retrieval. {\textcopyright} 2013 ACM.},
address = {New York, New York, USA},
author = {{Marcos Alvarez}, Alejandro and Yamada, Makoto and Kimura, Akisato},
booktitle = {International Workshop on Socially-aware Multimedia (IWSAM)},
doi = {10.1145/2509916.2509923},
file = {:Users/akisato/Library/Application Support/Mendeley Desktop/Downloaded/Marcos Alvarez, Yamada, Kimura - 2013 - Exploiting socially-generated side information in dimensionality reduction.pdf:pdf},
isbn = {9781450323949},
keywords = {dimensionality reduction,side information,social media},
pages = {9--12},
publisher = {ACM Press},
title = {{Exploiting Socially-generated Side Information in Dimensionality Reduction}},
url = {http://doi.acm.org/10.1145/2509916.2509923 http://dl.acm.org/citation.cfm?doid=2509916.2509923},
year = {2013}
}
@article{Kimura2013c,
abstract = {We humans are easily able to instantaneously detect the regions in a visual scene that are most likely to contain something of interest. Exploiting this pre-selection mechanism called visual attention for image and video processing systems would make them more sophisticated and therefore more useful. This paper briefly describes various computational models of human visual attention and their development, as well as related psychophysical findings. In particular, our objective is to carefully distinguish several types of studies related to human visual attention and saliency as a measure of attentiveness, and to provide a taxonomy from several viewpoints such as the main objective, the use of additional cues and mathematical principles. This survey finally discusses possible future directions for research into human visual attention and saliency computation.},
author = {Kimura, Akisato and Yonetani, Ryo and Hirayama, Takatsugu},
doi = {10.1587/transinf.E96.D.562},
issn = {17451361},
journal = {IEICE Transactions on Information and Systems},
keywords = {Bottom-up,Computational model,Human visual attention,Saliency,Top-down},
number = {3},
pages = {562--578},
title = {{Computational Models of Human Visual Attention and Their Implementations: A Survey}},
url = {http://hdl.handle.net/2433/171749},
volume = {E96-D},
year = {2013}
}
@inproceedings{Takeuchi2013a,
abstract = {Non-negative Tensor Factorization (NTF) is a widely used technique for decomposing a non-negative value tensor into sparse and reasonably interpretable factors. However, NTF performs poorly when the tensor is extremely sparse, which is often the case with real-world data and higher-order tensors. In this paper, we propose Non-negative Multiple Tensor Factorization (NMTF), which factorizes the target tensor and auxiliary tensors simultaneously. Auxiliary data tensors compensate for the sparseness of the target data tensor. The factors of the auxiliary tensors also allow us to examine the target data from several different aspects. We experimentally confirm that NMTF performs better than NTF in terms of reconstructing the given data. Furthermore, we demonstrate that the proposed NMTF can successfully extract spatio-temporal patterns of people's daily life such as leisure, drinking, and shopping activity by analyzing several tensors extracted from online review data sets. {\textcopyright} 2013 IEEE.},
author = {Takeuchi, Koh and Tomioka, Ryota and Ishiguro, Katsuhiko and Kimura, Akisato and Sawada, Hiroshi},
booktitle = {IEEE International Conference on Data Mining (ICDM)},
doi = {10.1109/ICDM.2013.83},
isbn = {978-0-7695-5108-1},
issn = {15504786},
keywords = {Machine Learning,Non-negative Tensor Factorization,Spatio-Temporal Pattern},
month = {dec},
pages = {1199--1204},
publisher = {IEEE},
title = {{Non-negative Multiple Tensor Factorization}},
url = {http://ieeexplore.ieee.org/document/6729621/},
year = {2013}
}
@inproceedings{Yamada2013,
abstract = {Change-point detection is the problem of finding abrupt changes in time-series, and it is attracting a lot of attention in the artificial intelligence and data mining communities. In this paper, we present a supervised learning based change-point detection approach in which we use the separability of past and future data at time t (they are labeled as +1 and -1) as plausibility of change-points. Based on this framework, we propose a detection measure called the additive Hilbert-Schmidt Independence Criterion (aHSIC), which is defined as the weighted sum of the HSIC scores between features and its corresponding binary labels. Here, the HSIC is a kernelbased independence measure. A novel aspect of the aHSIC score is that it can incorporate feature selection during its detection measure estimation. More specifically, we first select features that are responsible for an abrupt change by using a supervised approach, and then compute the aHSIC score by employing the selected features. Thus, compared with traditional detection measures, our approach tends to be robust as regards noise features, and so the aHSIC is suitable for a use with high-dimensional time-series change-point detection problems. We demonstrate that the proposed change-point detection method is promising through extensive experiments on synthetic data sets and a real-world human activity data set.},
author = {Yamada, Makoto and Kimura, Akisato and Naya, Futoshi and Sawada, Hiroshi},
booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},
isbn = {9781577356332},
issn = {10450823},
keywords = {Change-Point Detection,Feature Selection,High-dimensional Data},
title = {{Change-point detection with feature selection in high-dimensional time-series data}},
url = {https://www.aaai.org/ocs/index.php/IJCAI/IJCAI13/paper/viewPaper/6534},
year = {2013}
}
@inproceedings{Duh2012,
author = {Duh, Kevin and Hirao, Tsutomu and Kimura, Akisato and Ishiguro, Katsuhiko and Iwata, Tomoharu and Yeung, Ching-Man Au},
booktitle = {International AAAI Conference on Weblogs and Social Media (ICWSM)},
keywords = {Social media,curation},
pages = {447--450},
title = {{Creating Stories: Social Curation of Twitter Messages}},
url = {https://www.aaai.org/ocs/index.php/ICWSM/ICWSM12/paper/view/4578},
year = {2012}
}
@techreport{2012a,
author = {木村, 昭悟 and 米谷, 竜 and 平山, 高嗣},
booktitle = {電子情報通信学会技術研究報告 PRMU},
pages = {89--100},
title = {[サーベイ発表] 人間の視覚的注意の計算モデル},
year = {2012}
}
@inproceedings{Kimura2012,
abstract = {This paper provides a generic framework of component analysis (CA) methods introducing a new expression for scatter matrices and Gram matrices, called Generalized Pairwise Expression (GPE). This expression is quite compact but highly powerful: The framework includes not only (1) the standard CA methods but also (2) several regularization techniques, (3) weighted extensions, (4) some clustering methods, and (5) their semi-supervised extensions. This paper also presents quite a simple methodology for designing a desired CA method from the proposed framework: Adopting the known GPEs as templates, and generating a new method by combining these templates appropriately.},
author = {Kimura, Akisato and Sakano, Hitoshi and Kameoka, Hirokazu and Sugiyama, Masashi},
booktitle = {IAPR International Conference on Pattern Recognition (ICPR)},
isbn = {9784990644109},
issn = {10514651},
title = {{Designing various component analysis at will}},
url = {https://ieeexplore.ieee.org/document/6460786},
year = {2012}
}
@techreport{2012,
author = {石黒, 勝彦 and 木村, 昭悟 and 竹内, 孝},
booktitle = {画像の認識・理解シンポジウム (MIRU) 予稿集},
title = {{Social curationを用いた画像コンテンツの内容理解モデル: 画像特徴量を利用しない画像コンテンツ理解}},
year = {2012}
}
@techreport{2012b,
author = {米谷, 竜 and 木村, 昭悟 and 坂野, 鋭 and 福地, 賢},
booktitle = {画像の認識・理解シンポジウム (MIRU) 予稿集},
title = {深度画像推定を用いた自動物体セグメンテーション},
year = {2012}
}
@inproceedings{Ishiguro2012,
abstract = {The amount and variety of multimedia data such as images, movies and music available on over social networks are increasing rapidly. However, the ability to analyze and exploit these unorganized multimedia data remains inadequate, even with state-of-the-art media processing techniques. Our finding in this paper is that the emerging social curation service is a promising information source for the automatic understanding and mining of images distributed and exchanged via social media. One remarkable virtue of social curation service datasets is that they are weakly supervised: the content in the service is manually collected, selected and maintained by users. This is very different from other social information sources, and we can utilize this characteristics for media content mining without expensive media processing techniques. In this paper we present a machine learning system for predicting view counts of images in social curation data as the first step to automatic image content evaluation. Our experiments confirm that the simple features extracted from a social curation corpus are much superior in terms of count prediction than the goldstandard image features of computer vision research. {\textcopyright} 2012 IEEE.},
author = {Ishiguro, Katsuhiko and Kimura, Akisato and Takeuchi, Koh},
booktitle = {IEEE International Conference on Data Mining (ICDM)},
doi = {10.1109/ICDM.2012.37},
isbn = {9780769549057},
issn = {15504786},
keywords = {Automatic image understanding and evaluation,Feature extraction,Regression,Social curation},
pages = {906--911},
title = {{Towards automatic image understanding and mining via social curation}},
year = {2012}
}
@inproceedings{Yonetani2012,
abstract = {A novel framework for automatic object segmentation is proposed that exploits depth information estimated from a single image as an additional cue. For example, suppose that we have an image containing an object and a background with a similar color or tex- ture to the object. The proposed framework enables us to automatically extract the object from the image while eliminating the misleading background. Although our segmenta- tion framework takes a form of a traditional formulation based on Markov random fields, the proposed method provides a novel scheme to integrate depth and color information, which derives objectness/backgroundness likelihood. We also employ depth estimation via supervised learning so that the proposed method can work even if it has only a single input image with no actual depth information. Experimental results with a dataset origi- nally collected for the evaluation demonstrate the effectiveness of the proposed method against the baseline method and several existing methods for salient region detection.},
author = {Yonetani, Ryo and Kimura, Akisato and Sakano, Hitoshi and Fukuchi, Ken},
booktitle = {British Machine Vision Conference (BMVC)},
doi = {10.5244/C.26.28},
isbn = {1-901725-46-4},
pages = {28.1--28.11},
publisher = {British Machine Vision Association},
title = {{Single Image Segmentation with Estimated Depth}},
url = {http://www.bmva.org/bmvc/2012/BMVC/paper028/index.html},
year = {2012}
}
@inproceedings{Sakano2012,
abstract = {Fisher's linear discriminant analysis (FLDA) has been attracting many researchers and practitioners for several decades thanks to its ease of use and low computational cost. However, FLDA implicitly assumes that all the classes share the same covariance: which implies that FLDA might fail when this assumption is not necessarily satisfied. To overcome this problem, we propose a simple extension of FLDA that exploits a detailed covariance structure of every class by utilizing revealed by the class-wise auto-correlation matrices. The proposed method achieves remarkable improvements classification accuracy against FLDA while preserving two major strengths of FLDA: the ease of use and low computational costs. Experimental results with MNIST and other several data sets in UCI machine learning repository demonstrate the effectiveness of our method. {\textcopyright} 2012 Springer-Verlag Berlin Heidelberg.},
author = {Sakano, Hitoshi and Ohashi, Tsukasa and Kimura, Akisato and Sawada, Hiroshi and Ishiguro, Katsuhiko},
booktitle = {IAPR International Workshop on Statistical Techniques in Pattern Recognition (SPR)},
doi = {10.1007/978-3-642-34166-3_45},
isbn = {9783642341656},
issn = {03029743},
pages = {409--416},
title = {{Extended Fisher Criterion Based on Auto-correlation Matrix Information}},
url = {http://link.springer.com/10.1007/978-3-642-34166-3{\_}45},
year = {2012}
}
@techreport{2011,
author = {米谷, 竜 and 木村, 昭悟 and 坂野, 鋭 and 福地, 賢},
booktitle = {電子情報通信学会技術研究報告 PRMU},
title = {シーンの色情報と深度情報の統合による自動物体セグメンテーション},
year = {2011}
}
@techreport{sun2011trecvid,
author = {Sun, Yongqing and Irie, Go and Satou, Takashi and Kojima, Akira and Sudo, Kyoko and Morimoto, Masashi and Kimura, Akisato and Zhang, Zhihua},
title = {{TRECVID 2011 Semantic Indexing - NTT Cyber Communication Laboratory Group in collaboration with Zhejiang University}},
year = {2011}
}
@techreport{kawanishi2011ntt,
author = {Kawanishi, Takahito and Kashino, Kunio and Sun, Yong Qing and Le, Duy-dinh and Zhu, Caizhi},
title = {{NTT Communication Science Laboratories and NII at TRECVID 2011 Instance Search Task}},
year = {2011}
}
@inproceedings{Takagi2011,
abstract = {We propose a novel semi-supervised method for building a statistical model that represents the relationship between sounds and text labels (“tags”). The proposed method, named semi-supervised canonical density estimation, makes use of unlabeled sound data in two ways: 1) a low-dimensional latent space representing topics of sounds is extracted by a semi-supervised variant of canonical correlation analysis, and 2) topic models are learned by multi-class extension of semi-supervised kernel density estimation in the topic space. Real-world audio tagging experiments indicate that our pro- posed method improves the accuracy even when only a small number of labeled sounds are available.},
address = {Prague, Czech Republic},
author = {Takagi, Jun and Ohishi, Yasunori and Kimura, Akisato and Sugiyama, Masashi and Yamada, Makoto and Kameoka, Hirokazu},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2011.5946925},
isbn = {9781457705397},
issn = {15206149},
keywords = {Audio tag classifcation,Audio tag classification,canonical correlation analysis,kernel density estimation,semi-supervised learning,topic model},
pages = {2232--2235},
title = {{Automatic audio tag classification via semi-supervised canonical density estimation}},
year = {2011}
}
@inproceedings{Nakano2011,
abstract = {We propose a new statistical model, named Hierarchical Topic Trajectory Model (HTTM), for acquiring a dynamically changing topic model that represents the relationship between video frames and associated text labels. Model parameter estimation, annotation and retrieval can be executed within a unified framework with a few computation. It is also easy to add new modals such as audio signal and geotags. Preliminary experiments on video annotation task with manually annotated video dataset indicate that our proposed method can improve the annotation accuracy.},
author = {Nakano, Takuho and Kimura, Akisato and Kameoka, Hirokazu and Miyabe, Shigeki and Sagayama, Shigeki and Ono, Nobutaka and Kashino, Kunio and Nishimoto, Takuya},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2011.5946962},
isbn = {9781457705397},
issn = {15206149},
keywords = {Video annotation,canonical correlation analysis,generative approach,hidden Markov model,topic model},
title = {{Automatic video annotation via hierarchical topic trajectory model considering cross-modal correlations}},
year = {2011}
}
@article{Watchareeruetai2011,
abstract = {We propose a novel framework called StochasticSIFT for detecting interest points (IPs) in video sequences. The proposed framework incorporates a stochastic model considering the temporal dynamics of videos into the SIFT detector to improve robustness against fluctuations inherent to video signals. Instead of detecting IPs and then removing unstable or inconsistent IP candidates, we introduce IP stability derived from a stochastic model of inherent fluctuations to detect more stable IPs. The experimental results show that the proposed IP detector outperforms the SIFT detector in terms of repeatability and matching rates. {\textcopyright} 2011 Information Processing Society of Japan.},
author = {Watchareeruetai, Ukrit and Kimura, Akisato and Bao, Robert Cheng and Kawanishi, Takahito and Kashino, Kunio},
doi = {10.2197/ipsjtcva.3.186},
issn = {1882-6695},
journal = {IPSJ Transactions on Computer Vision and Applications (CVA)},
pages = {186--197},
title = {{Interest Point Detection Based on Stochastically Derived Stability}},
url = {http://joi.jlc.jst.go.jp/JST.JSTAGE/ipsjtcva/3.186?from=CrossRef},
volume = {3},
year = {2011}
}
@inproceedings{Kimura2010,
abstract = {Canonical correlation analysis (CCA) is a powerful tool for analyzing multi-dimensional paired data. However, CCA tends to perform poorly when the number of paired samples is limited, which is often the case in practice. To cope with this problem, we propose a semi-supervised variant of CCA named "Semi CCA" that allows us to incorporate additional unpaired samples for mitigating overfitting. The proposed method smoothly bridges the eigenvalue problems of CCA and principal component analysis (PCA), and thus its solution can be computed efficiently just by solving a single (generalized) eigenvalue problem as the original CCA. Preliminary experiments with artificially generated samples and PASCAL VOC data sets demonstrate the effectiveness of the proposed method.},
author = {Kimura, Akisato and Kameoka, Hirokazu and Sugiyama, Masashi and Nakano, Takuho and Maeda, Eisaku and Sakano, Hitoshi and Ishiguro, Katsuhiko},
booktitle = {IAPR International Conference on Pattern Recognition (ICPR)},
doi = {10.1109/ICPR.2010.719},
isbn = {978-1-4244-7542-1},
month = {aug},
pages = {2933--2936},
publisher = {IEEE},
title = {{SemiCCA: Efficient Semi-supervised Learning of Canonical Correlations}},
url = {http://ieeexplore.ieee.org/document/5595904/},
year = {2010}
}
@techreport{2010,
author = {木村, 昭悟},
booktitle = {信号処理シンポジウム予稿集},
title = {人間の視覚的注意の確率モデル: 動的ベイジアンネットワークに基づく最新のアプローチ},
year = {2010}
}
@techreport{2010a,
abstract = {本論文では音響信号自動タグ付け・検索問題に対し,半教師付き正準密度推定法SSCDE(Semi-supervised canonical density estimation)の適用を試みる.SSCDEは正準相関分析にタグ無しサンプルの大域的分布構造を組み込んだ半教師型正準相関分析(SemiCCA)によりトピックを表現する潜在変数の空間を構築し,カーネル密度推定法を半教師化した多クラスSSKDEによって潜在変数空間上のモデル学習を行う,トピックモデルに基づく半教師型の学習手法である.この手法は画像認識・検索の分野において提案されたものであるが,音響信号に対する適用もスムーズに行うことができる.実際の音楽データを用いた実験により,使用できるタグ付き音響信号が少ない状況下でも,SSCDEを用いて半教師型の学習を行うことにより,タグ付け性能が向上することを確認した.},
author = {高木, 潤 and 大石, 康智 and 木村, 昭悟 and 杉山, 将 and 山田, 誠 and 亀岡, 弘和},
booktitle = {電子情報通信学会技術研究報告 PRMU},
issn = {09135685},
keywords = {カーネル密度推定,トピックモデル推定,半教師付き学習,正準相関分析,音響信号自動タグ付け・検索},
number = {330},
pages = {1--6},
publisher = {社団法人電子情報通信学会},
title = {半教師付き正準密度推定法に基づく音響信号の自動タグ付けと検索},
url = {http://ci.nii.ac.jp/naid/110008675742/},
volume = {110},
year = {2010}
}
@techreport{Nakano2010,
abstract = {We applied a generative approach to the TRECVID 2010 Semantic Indexing (SIN) and Known-Item Search (KIS) tasks, using a probabilistic network called Hierarchical Topic Trajectory Model (HTTM). It is our newly-developed model that can integrate multiple sources of potentially associated information such as video frames and texts, as well as dynamically changing high-level pieces of information such as topics. With this model, the semantic indexing and the knownitem search tasks were dealt within a single unified framework. We show how it worked, and present some analysis for the SIN task.},
author = {Nakano, T. and Kimura, A. and Kameoka, H. and Sagayama, S. and Ono, N. and Kashino, K.},
booktitle = {2010 TREC Video Retrieval Evaluation Notebook Papers},
keywords = {Canonical correlation analysis,Generative approach,Hidden Markov model,Known-item search,Semantic indexing,Topic model},
title = {{Semantic indexing and known item search based on a unified model with topic transition representation}},
year = {2010}
}
@techreport{SSCDE2010,
author = {昭悟, 木村 and 拓帆, 中野 and 将, 杉山 and 弘和, 亀岡 and 英作, 前田 and 鋭, 坂野},
booktitle = {画像の認識・理解シンポジウム (MIRU) 予稿集},
title = {{SSCDE: 画像認識検索のための半教師付正準密度推定法}},
year = {2010}
}
@techreport{Sekhon2010,
author = {Sekhon, Gurbachan and Kimura, Akisato and Fukuchi, Ken},
booktitle = {画像の認識・理解シンポジウム (MIRU) 予稿集},
title = {{Automatic and precise extraction of generic objects using saliency-based priors and contour constraints}},
year = {2010}
}
@incollection{2010b,
author = {木村, 昭悟 and 亀岡, 弘和 and 柏野, 邦夫},
issn = {09152318},
journal = {NTT技術ジャ-ナル},
keywords = {メディア形態素,メディア認識理解,学習},
number = {9},
pages = {15--18},
publisher = {電気通信協会},
title = {音や映像から「部品」を取り出すメディアシーン学習技術},
url = {http://ci.nii.ac.jp/naid/40017291363/ https://www.ntt.co.jp/journal/1009/files/jn201009015.pdf},
volume = {22},
year = {2010}
}
@article{2010c,
abstract = {本論文では,映像中から顕著な領域を自動的,高速かつ高精度に抽出するための方法を提案する.提案手法では,以下の2点により高速かつ高精度な自動抽出を実現している.(1)グラフカットに基づく画像分割手法に,入力画像の各位置が抽出すべき領域である確率を示す事前確率を顕著度に基づいて与える処理を導入し,分割の自動化を実現する.(2)過去の分割結果に基づいて事前確率と特徴量ゆう度を逐次的に更新する処理を導入し,安定性の高い分割を実現する.実験により,全自動処理である提案手法が,手動・半自動処理に基づく既存手法と比較して,精度を大きく犠牲にすることなく,かつ圧倒的に高速に領域を抽出できることを示す.},
author = {福地, 賢 and 宮里, 洸司 and 赤嶺, 一馬 and 木村, 昭悟 and 高木, 茂 and 大和, 淳司 and 柏野, 邦夫},
issn = {18804535},
journal = {電子情報通信学会論文誌 D},
keywords = {グラフカット,マルコフ確率場,映像分割,最大事後確率推定,顕著度},
number = {8},
pages = {1523--1532},
publisher = {社団法人電子情報通信学会},
title = {グラフコストの逐次更新を用いた映像顕著領域の自動抽出},
url = {http://ci.nii.ac.jp/naid/110007681689/},
volume = {93},
year = {2010}
}
@techreport{2010d,
author = {木村, 昭悟 and 南, 泰浩 and 坂野, 鋭 and 前田, 英作 and 杉山弘晃},
journal = {電子情報通信学会技術研究報告 PRMU},
number = {330},
pages = {53--54},
publisher = {一般社団法人電子情報通信学会},
title = {対話型映像認識理解における動的学習戦略に関する取り組み},
volume = {110},
year = {2010}
}
@techreport{Sekhon2010a,
author = {Sekhon, Gurbachan and 木村, 昭悟 and 南, 泰浩 and 坂野, 鋭 and 前田},
booktitle = {電子情報通信学会技術研究報告 PRMU},
issn = {09135685},
keywords = {Image annotation,action planning,human-computer interaction,knowledge confidence,reinforcement learning,topic model},
number = {188},
pages = {201--208},
publisher = {一般社団法人電子情報通信学会},
title = {保有知識の確信度に基づく対話型映像認識理解システムの質問生成戦略},
url = {http://ci.nii.ac.jp/naid/110008107179/},
volume = {110},
year = {2010}
}
@incollection{Kimura2010a,
abstract = {We describe a novel framework called Media Scene Learning (MSL) for automatically extracting key components such as the sound of a single instrument from a given audio signal or a target object from a given video signal. In particular, we introduce two key methods: 1) the Composite Auto-Regressive System (CARS) for decomposing audio signals into several sound components on the basis of a generative model of sounds and 2) Saliency-Based Image Learning (SBIL) for extracting object-like regions from a given video signal on the basis of the characteristics of the human visual system.},
author = {Kimura, Akisato and Kameoka, Hirokazu and Kashino, Kunio},
issn = {13483447},
journal = {NTT Technical Review},
number = {11},
title = {{Media Scene Learning: A novel framework for automatically extracting meaningful parts from audio and video signals}},
volume = {8},
year = {2010}
}
@inproceedings{Kuzuoka2010,
abstract = {A multiterminal lossy source coding problem, which includes various problems such as the Wyner-Ziv problem and the complementary delivery problem as special cases, is considered. It is shown that any point in the achievable ratedistortion region can be attained even if the source statistics are not known.},
author = {Kuzuoka, Shigeaki and Kimura, Akisato and Uyematsu, Tomohiko},
booktitle = {IEEE International Symposium on Information Theory (ISIT)},
doi = {10.1109/ISIT.2010.5513306},
isbn = {978-1-4244-7892-7},
issn = {21578103},
month = {jun},
pages = {1--5},
publisher = {IEEE},
title = {{Universal source coding for multiple decoders with side information}},
url = {http://ieeexplore.ieee.org/document/5513306/},
year = {2010}
}
@techreport{2009,
abstract = {人間は、網膜に映る像の中から重要と思われる領域を瞬時に判断することで、効率的に情報を獲得している。これら高度な視覚機構を計算機上で実現することで、重要性に応じて映像中の情報を能動的に取捨選択でき、数多くのシステムをより高度化できる。本報告では、人間の視覚機構を高精度に模擬する新しい計算モデル、及び実時間動作を実現するstream processingに基づく実装方法を提案する。提案法では、新たにマルコフ連鎖モンテカルロ法に基づくサンプリングと、粒子フィルタに基づく事後確率推定を新たに導入することで、並列処理を実現可能とした。大規模視線測定データベースを用いた人間の注視行動との比較実験により、本提案手法が従来手法と比較して、10倍以上高速かつほぼ同精度で人間の映像注視行動を推定できることを示す。},
author = {宮里, 洸司 and 木村, 昭悟 and 高木, 茂 and 大和, 淳司},
booktitle = {電子情報通信学会技術研究報告 PRMU},
issn = {09135685},
keywords = {stream processing,マルコフ連鎖モンテカルロ,動的ベイジアンネットワーク,粒子フィルタ,顕著度},
number = {64},
pages = {83--88},
publisher = {社団法人電子情報通信学会},
title = {{MCMC-based particle filterを用いた人間の映像注視行動の実時間推定}},
url = {http://ci.nii.ac.jp/naid/110007338757/},
volume = {109},
year = {2009}
}
@inproceedings{Miyazato2009,
author = {Miyazato, Kouji and Kimura, Akisato and Takagi, Shigeru and Yamato, Junji},
booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2009.5202483},
isbn = {978-1-4244-4290-4},
month = {jun},
pages = {250--257},
publisher = {IEEE},
title = {{Real-time estimation of human visual attention with dynamic Bayesian network and MCMC-based particle filter}},
url = {https://ieeexplore.ieee.org/document/5202483 http://ieeexplore.ieee.org/document/5202483/},
year = {2009}
}
@techreport{2009a,
abstract = {人間は、網膜に映る像の中から重要と思われる領域を瞬時に判断することで、 効率的に情報を獲得している。これら高度な視覚機構を計算機上で実現する ことで、重要性に応じて映像中の情報を能動的に取捨選択でき、数多くの システムをより高度化できる。本報告では、人間の視覚機構を高精度に模擬する 新しい計算モデル、及び実時間動作を実現するstream processingに基づく実装 方法を提案する。提案法では、新たにマルコフ連鎖モンテカルロ法に基づく サンプリングと、粒子フィルタに基づく事後確率推定を新たに導入することで、 並列処理を実現可能とした。大規模視線測定データベースを用いた人間の注視 行動との比較実験により、本提案手法が従来手法と比較して、10倍以上高速かつ ほぼ同精度で人間の映像注視行動を推定できることを示す。},
author = {宮里, 洸司 and 木村, 昭悟 and 高木, 茂 and 大和, 淳司 and 邦夫, 柏野},
booktitle = {画像の認識・理解シンポジウム (MIRU) 予稿集},
pages = {143----150},
title = {{MCMC-based particle filterを用いた人間の映像注視行動の実時間推定}},
year = {2009}
}
@techreport{2009b,
abstract = {人間は、特に意識をしなくとも、見た映像を理解し言語化でき、与えられた映像群の中から自身の思い描く映像を的確に見つけ出すことができる。しかし、これらのタスクを計算機に代行させる映像認識理解問題や映像検索問題は、パターン認識分野における早期からの最重要課題の1つでありながら、未だ本質的な解決に至っていない。ただ、人間も映像認識・理解・検索の能力を先天的に兼ね備えているとは考えにくく、その大部分が成長の過程で後天的に身に付けていく性質のものであると考えられる。本報告では、この点に着目し、認知発達的アプローチに基づく新しい映像認識理解、特にそのための知識獲得戦略のあり方を提案する。本報告で提案する枠組において、従来のアプローチと異なる特に重要な点は、以下の2点である。(1)映像の認識・理解に必要な知識の能動的かつ自律的な獲得、(2)自らの発達段階に応じた知識獲得戦略の動的遷移。本報告では、このアプローチの初期的な試みとして、発達初期段階における乳幼児の典型的な行動を参考にして作成した知識獲得システムのプロトタイプについて紹介すると共に、提案する枠組の具体的な方向性とその実現可能性について議論する。},
author = {木村, 昭悟 and 柏野, 邦夫 and 福地, 賢 and 赤嶺, 一馬 and 高木茂},
booktitle = {電子情報通信学会技術研究報告. PRMU, パターン認識・メディア理解},
issn = {09135685},
keywords = {映像認識理解,発達段階,知識獲得戦略,認知発達},
month = {dec},
number = {344},
pages = {37--42},
publisher = {一般社団法人電子情報通信学会},
title = {映像認識理解への認知発達的アプローチ},
url = {http://ci.nii.ac.jp/naid/110008002723/},
volume = {109},
year = {2009}
}
@inproceedings{Fukuchi2009,
abstract = {This paper proposes a new method for achieving precise video segmentation without any supervision or interaction. The main contributions of this report include 1) the introduction of fully automatic segmentation based on the maximum a posteriori (MAP) estimation of the Markov random field (MRF) with graph cuts and saliency-driven priors and 2) the updating of priors and feature likelihoods by integrating the previous segmentation results and the currently estimated saliency-based visual attention. Test results indicate that our new method precisely extracts probable regions from videos without any supervised interactions.},
address = {Prague, Czech Republic},
author = {Fukuchi, Ken and Miyazato, Kouji and Kimura, Akisato and Takagi, Shigeru and Yamato, Junji},
booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2009.5202577},
isbn = {978-1-4244-4290-4},
issn = {2327-0985},
keywords = {!!cite,saliency map,segmentation},
mendeley-tags = {!!cite,saliency map,segmentation},
month = {jun},
number = {1},
pages = {638--641},
publisher = {IEEE},
title = {{Saliency-based video segmentation with graph cuts and sequentially updated priors}},
url = {http://ieeexplore.ieee.org/document/5202577/},
volume = {4},
year = {2009}
}
@article{Kimura2009,
abstract = {This paper deals with a universal coding problem for a certain kind of multiterminal source coding network called a generalized complementary delivery network. In this network, messages from multiple correlated sources are jointly encoded, and each decoder has access to some of the messages to enable it to reproduce the other messages. Both fixed-to-fixed length and fixed-to-variable length lossless coding schemes are considered. Explicit constructions of universal codes and the bounds of the error probabilities are clarified by using methods of types and graph-theoretical analysis. {\textcopyright} 2009 IEEE.},
author = {Kimura, Akisato and Uyematsu, Tomohiko and Kuzuoka, Shigeaki and Watanabe, Shun},
doi = {10.1109/TIT.2008.2011438},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Complementary delivery,Correlated sources,Lossless coding,Methods of types,Multiterminal source coding,Network source coding,Universal coding},
number = {3},
title = {{Universal source coding over generalized complementary delivery networks}},
volume = {55},
year = {2009}
}
@inproceedings{Kimura2008,
abstract = {This report proposes a new stochastic model of visual attention to predict the likelihood of where humans typically focus on a video scene. The proposed model is composed of a dynamic Bayesian network that simulates and combines a person's visual saliency response and eye movement patterns to estimate the most probable regions of attention. Dynamic Markov random field (MRF) models are newly introduced to include spatiotemporal relationships of visual saliency responses. Experimental results have revealed that the propose model outperforms the previous deterministic model and the stochastic model without dynamic MRF in predicting human visual attention.},
author = {Kimura, Akisato and Pang, Derek and {Tatsuto Takeuchi} and {Junji Yamato} and {Kunio Kashino}},
booktitle = {IAPR International Conference on Pattern Recognition (ICPR)},
doi = {10.1109/ICPR.2008.4761025},
isbn = {978-1-4244-2174-9},
issn = {1051-4651},
month = {dec},
pages = {1--5},
publisher = {IEEE},
title = {{Dynamic Markov random fields for stochastic modeling of visual attention}},
url = {https://ieeexplore.ieee.org/document/4761025},
year = {2008}
}
@techreport{2008,
author = {木村, 昭悟 and Pang, Derek and 竹内, 龍人 and 大和, 淳司 and 柏野, 邦夫},
booktitle = {電子情報通信学会技術研究報告 PRMU},
title = {{Dynamic Markov random fields for stochastic modeling of visual attention}},
year = {2008}
}
@techreport{kimura2008multiterminal,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
journal = {Arxiv preprint arXiv:0804.1602},
title = {{Multiterminal source coding with complementary delivery}},
url = {https://arxiv.org/abs/0804.1602},
year = {2008}
}
@techreport{Kimura2008a,
author = {Kimura, Akisato},
booktitle = {情報理論とその応用シンポジウム (SITA)},
title = {{Particle-based simulation of the Gel'fand-Pinsker channel capacity and the Wyner-Ziv rate-distortion function}},
year = {2008}
}
@inproceedings{Kuzuoka2008,
abstract = {This paper deals with a universal lossy coding problem for a certain kind of multiterminal source coding network called a complementary delivery system. A universal coding scheme based on Wyner-Ziv codes is proposed. While the proposed scheme cannot attain the optimal rate-distortion trade off in general, the rate-loss is upper bounded by a universal constant under some mild conditions. Moreover, the proposed scheme allows us to apply (non-universal) Wyner-Ziv codes to construct a universal lossy complementary delivery code.},
author = {Kuzuoka, Shigeaki and Kimura, Akisato and Uyematsu, Tomohiko},
booktitle = {IEEE International Symposium on Information Theory (ISIT)},
doi = {10.1109/ISIT.2008.4595376},
isbn = {9781424422579},
issn = {2157-8095},
keywords = {Complementary delivery,Decoding,Electronic mail,Encoding,Joints,Minimization,Multiterminal source coding,Network coding,Random variables,Source coding,Universal coding,Wyner-Ziv codes,Wyner-Ziv coding,complementary delivery,complementary delivery system,multiterminal networks,multiterminal source coding,multiterminal source coding network,network coding,source coding,universal coding,universal coding scheme,universal lossy coding problem},
month = {jul},
pages = {2177--2181},
title = {{Universal coding for lossy complementary delivery problem}},
year = {2008}
}
@inproceedings{Pang2008,
author = {Pang, Derek and Kimura, Akisato and Takeuchi, Tatsuto and Yamato, Junji and Kashino, Kunio and {Derek Pang} and {Akisato Kimura} and {Tatsuto Takeuchi} and {Junji Yamato} and {Kunio Kashino}},
booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2008.4607624},
isbn = {9781424425716},
issn = {1945-7871},
keywords = {!!cite,Bayes methods,Bayesian methods,Focusing,Hidden Markov models,Kalman filter,Predictive models,Stochastic processes,Training data,Visual attention model,Visualization,cognitive state,dynamic Bayesian network,hidden Markov model,hidden Markov models,likelihood prediction,maximum likelihood detection,saliency,saliency map,selective visual attention,signal detection,stochastic model,video scene,video signal processing,visual perception,visual saliency response},
mendeley-tags = {!!cite,saliency map},
month = {jun},
pages = {1073--1076},
publisher = {IEEE},
title = {{A stochastic model of selective visual attention with a dynamic Bayesian network}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4607624},
year = {2008}
}
@article{Kimura2008b,
abstract = {This paper presents a new method for a quick similarity-based search through long unlabeled audio streams to detect and locate audio clips provided by users. The method involves feature-dimension reduction based on a piecewise linear representation of a sequential feature trajectory extracted from a long audio stream. Two techniques enable us to obtain a piecewise linear representation: the dynamic segmentation of feature trajectories and the segment-based Karhunen-Loeve (KL) transform. The proposed search method guarantees the same search results as the search method without the proposed feature-dimension reduction method in principle. Experimental results indicate significant improvements in search speed. For example, the proposed method reduced the total search time to approximately 1/12 that of previous methods and detected queries in approximately 0.3 s from a 200-h audio database. {\textcopyright} 2008 IEEE.},
author = {Kimura, Akisato and Kashino, Kunio and Kurozumi, Takayuki and Murase, Hiroshi},
doi = {10.1109/TASL.2007.912362},
issn = {1558-7916},
journal = {IEEE Transactions on Audio, Speech, and Language Processing (TASLP)},
keywords = {Audio fingerprinting,Audio retrieval,Content identification,Dynamic segmentation,Feature trajectories,Piecewise linear representation},
month = {feb},
number = {2},
pages = {396--407},
title = {{A Quick Search Method for Audio Signals Based on a Piecewise Linear Representation of Feature Trajectories}},
url = {http://ieeexplore.ieee.org/document/4432644/},
volume = {16},
year = {2008}
}
@article{Kimura2007,
abstract = {This paper deals with a universal coding problem for a certain kind of multiterminal source coding system that we call the complementary delivery coding system. In this system, messages from two correlated sources are jointly encoded, and each decoder has access to one of the two messages to enable it to reproduce the other message. Both fixed-to-fixed length and fixed-to-variable length lossless coding schemes are considered. Explicit constructions of universal codes and bounds of the error probabilities are clarified via type-theoretical and graph-theoretical analyses. Copyright {\textcopyright} 2007 The Institute of Electronics, Information and Communication Engineers.},
author = {Kimura, Akisato and Uyematsu, Tomohiko and Kuzuoka, Shigeaki},
doi = {10.1093/ietfec/e90-a.9.1840},
issn = {0916-8508},
journal = {IEICE Transactions on Fundamentals},
keywords = {Bipartite graphs,Complementary delivery,Multiterminal source coding,Types of sequences,Universal coding},
month = {sep},
number = {9},
pages = {1840--1847},
title = {{Universal Coding for Correlated Sources with Complementary Delivery}},
url = {http://search.ieice.org/bin/summary.php?id=e90-a{\_}9{\_}1840{\&}category=A{\&}year=2007{\&}lang=E{\&}abst=},
volume = {E90-A},
year = {2007}
}
@inproceedings{Leung2007,
author = {Leung, Clement and Kimura, Akisato and Takeuchi, Tatsuto and Kashino, Kunio},
booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2007.4284646},
isbn = {1-4244-1016-9},
month = {jul},
pages = {300--303},
publisher = {IEEE},
title = {{A Computational Model of Saliency Depletion/Recovery Phenomena for the Salient Region Extraction of Videos}},
url = {https://ieeexplore.ieee.org/document/4284646},
year = {2007}
}
@inproceedings{Kashino2007,
abstract = {Signal similarity search is an important technique for music information retrieval. A basic task is finding identical signal segments on unlabeled music-signal archives, given a short music signal fragment as a query. In such a task, the search must be fast and sufficiently robust against possible signal fluctuations due to noise and distortions. In this special session paper, we describe a search method designed to cope with additive interferring sounds by spectral partitioning. Then, we introduce another method designed to be robust under multiplicative noise or distortion based on binary area representation. {\textcopyright} 2007 IEEE.},
author = {Kashino, Kunio and Kimura, Akisato and Nagano, Hidehisa and Kurozumi, Takayuki},
booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2007.367346},
isbn = {1-4244-0727-3},
issn = {15206149},
keywords = {Information retrieval,Multimedia databases,Music,Search methods},
month = {apr},
pages = {1421--1424},
publisher = {IEEE},
title = {{Robust Search Methods for Music Signals Based on Simple Representation}},
url = {http://ieeexplore.ieee.org/document/4218377/},
volume = {4},
year = {2007}
}
@incollection{2007,
abstract = {メディア探索技術は，目的のメディア情報（音や映像など）を，膨大な蓄 積の中から高速かつ正確に探し出すことを目指すもので，さまざまなサービ ス実現の核となる技術です．最近の話題を中心に，主な技術の概要と実用化 の事例を紹介します．},
author = {柏野, 邦夫 and 向井, 良 and 大塚, 和弘 and 永野, 秀尚 and 泉谷, 知範 and 木村, 昭悟 and 黒住, 隆行 and 大和, 淳司},
journal = {NTT技術ジャーナル},
number = {6},
pages = {23--32},
title = {高速メディア探索},
url = {https://www.ntt.co.jp/journal/0706/files/jn200706029.pdf},
volume = {19},
year = {2007}
}
@techreport{kimura2006information,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
booktitle = {Symposium on Information Theory and Its Applications (SITA)},
title = {{Information-theoretical analysis of index searching: Revised}},
year = {2006}
}
@techreport{Kimura2006,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
booktitle = {シャノン理論ワークショップ (STW)},
pages = {25--31},
title = {{Multiterminal source coding for cascading and feedback refinement systems}},
year = {2006}
}
@techreport{2006,
author = {黒住隆行 and 木村昭悟 and 永野秀尚 and 柏野邦夫},
journal = {電子情報通信学会技術研究報告 PRMU},
number = {429},
pages = {1--6},
publisher = {一般社団法人電子情報通信学会},
title = {幾何変換パラメータを特定する縮退生成探索法},
volume = {106},
year = {2006}
}
@incollection{2006a,
author = {松原, 繁夫 and 古川, 茂人 and 木村, 昭悟 and 鈴木, 潤},
journal = {NTT 技術ジャーナル},
number = {9},
pages = {69--71},
publisher = {電気通信協会},
title = {{「未来想論 2006 NTT コミュニケーション科学基礎研究所研究交流会」 開催報告}},
url = {https://www.ntt.co.jp/journal/0609/files/jn200609069.pdf},
volume = {18},
year = {2006}
}
@inproceedings{Kawanishi2005,
abstract = {We have developed a small cylindrical display for anthropomorphic agents that communicate with multiple users in a 3D environment. A previously reported cylindrical display was dark with poor contrast in the lower part of the screen because the pixel density is much lower than in the upper part. We improved the uniformity of the pixel density by using an aspherical mirror. Experimental results show that our new display has better luminance and better contrast than the previously reported display.},
author = {Kawanishi, Takahito and Tsuchida, Masaru and Takagi, Shigeru and Kimura, Akisato and Yamato, Junji},
booktitle = {International Display Workshops (IDW)},
number = {2},
title = {{Small cylindrical display using an aspherical mirror for anthropomorphic agents}},
year = {2005}
}
@article{2005,
abstract = {本論文では，サブテンプレート間の距離を用いた高速なテンプレートマッチング法を提案する．サブテンプレートと入力画像上のウィンドウの一部（サブウィンドウ）とを照合した結果，距離が十分大きい場合に，サブウィンドウを内部に含むウィンドウすべてに対して距離下限値を計算する．ウィンドウとテンプレートを照合する前に，そのウィンドウにおける距離下限値としきい値とを比較し，距離下限値がしきい値より大きい場合に，その照合を省略する．この照合の省略の結果，探索時間を大幅に削減することができる．実験の結果，テンプレートのサイズが指定できない場合や，しきい値の初期値を適切に設定することが難しい場合に従来のテンプレートマッチングの高速化手法と比べて全く同じ精度を保証して短い時間で探索できることが分かった．},
author = {川西, 隆仁 and 久野, 和樹 and 木村, 昭悟 and 黒住, 隆行 and 柏野, 邦夫 and 高木, 茂},
journal = {電子情報通信学会論文誌},
keywords = {SSDA,サブテンプレート,テンプレートマッチング,三角不等式,距離下限値},
number = {8},
pages = {1389--1397},
publisher = {The Institute of Electronics, Information and Communication Engineers},
title = {サブテンプレート間距離を用いた適応的ウィンドウスキップによる高速テンプレートマッチング法},
url = {https://search.ieice.org/bin/summary.php?id=j88-d2{\_}8{\_}1389{\&}category=D{\&}lang=J{\&}year=2005{\&}abst=},
volume = {88},
year = {2005}
}
@incollection{2005a,
author = {木村, 昭悟 and 川西, 隆仁 and 大塚, 和弘 and 柏野, 邦夫},
journal = {電子情報通信学会技術研究報告 PRMU},
number = {118},
pages = {7--12},
publisher = {一般社団法人電子情報通信学会},
title = {重み付き特徴点照合に基づく高速画像検索},
volume = {105},
year = {2005}
}
@article{2005b,
abstract = {本論文では，膨大な数の画像の中から目的とする画像に類似する部分画像を類似度に基づいて検出するための基本的な枠組みを提案する．高速検出を実現するためには，ある種のインデックス構造を導入することが必要となる．しかし，データベース中の各画像から膨大な量の部分領域を抽出してインデックス構造に投入する必要があるため，インデックスの保持に必要な記憶容量が膨大になるという問題点があった．提案法では，データベース中の画像について，部分領域を間引いて抽出することにより，インデックスの保持に必要な記憶容量を大幅に削減する．このとき，部分領域の抽出間隔を適切に設定することにより，総当り照合と全く同一の検索結果が出力されることを理論的に保証することが可能である．},
author = {木村, 昭悟 and 川西, 隆仁 and 柏野, 邦夫},
journal = {電子情報通信学会論文誌},
keywords = {region-based image retrieval,マージン,部分画像検索,部分領域},
number = {8},
pages = {1712--1719},
title = {{SPIRE：スパースなインデキシングによる画像中の同一部分領域の検出}},
volume = {88},
year = {2005}
}
@inproceedings{Kimura2004,
abstract = {We propose a new framework for quick and accurate partial image retrieval from a huge number of images based on a predefined distance measure. Finding partial similarities generally requires a huge amount of storage space for indexes due to the large number of portions of images. The proposed method extracts portions from each database image at a constant spacing, while it extracts all possible portions from a query image. In this way, the proposed method can greatly reduce the size of indexes while theoretically guaranteeing the same accuracy as exhaustive matching.},
author = {Kimura, Akisato and Kawanishi, Takahito and Kashino, Kunio},
booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2004.1394629},
isbn = {0-7803-8603-5},
pages = {1895--1898},
publisher = {IEEE},
title = {{Similarity-based partial image retrieval guaranteeing same accuracy as exhaustive matching}},
url = {http://ieeexplore.ieee.org/document/1394629/},
volume = {3},
year = {2004}
}
@inproceedings{Kimura2004a,
abstract = {We propose a new method for quick and accurate partial image retrieval from a huge number of images based on a predefined distance measure. The proposed method utilizes vector quantization (VQ) on multiple layers, namely color, block, and feature layers. This can greatly reduce the amount of calculation needed for partial image retrieval. Experiments indicate that the proposed method can detect partial images that are similar to queries through 1000 images within 4 seconds. This is approximately 30 times faster than the method to which multistage VQ is not applied.},
author = {Kimura, Akisato and Kawanishi, Takahito and Kashino, Kunio},
booktitle = {IAPR International Conference on Pattern Recognition (ICPR)},
doi = {10.1109/ICPR.2004.1334426},
isbn = {0-7695-2128-2},
issn = {10514651},
pages = {993--996 Vol.2},
publisher = {IEEE},
title = {{Acceleration of similarity-based partial image retrieval using multistage vector quantization}},
url = {http://ieeexplore.ieee.org/document/1334426/},
volume = {2},
year = {2004}
}
@inproceedings{Kashino2004,
abstract = {This paper proposes a quick method of similarity-based video searching to detect and locate a specific video clip given as a query in a stored long video stream. The method employs a two-stage process: local and global feature clustering. The local clustering exploits continuity or local similarities between video features, and the global clustering gathers similar video frames that are not necessarily adjacent to each other. These processes prune irrelevant sections on a video stream. The method guarantees the exactly same search result as the exhaustive search. Experiments performed on a PC show that the proposed method can correctly detect and locate a 7.5-second clip in a 150-hour video recording in 15 ms on average.},
author = {Kashino, Kunio and Kimura, Akisato and Kurozumi, Takayuki},
booktitle = {IAPR International Conference on Pattern Recognition (ICPR)},
doi = {10.1109/ICPR.2004.1334672},
isbn = {0-7695-2128-2},
issn = {10514651},
pages = {894--897},
publisher = {IEEE},
title = {{A quick video search method based on local and global feature clustering}},
url = {http://ieeexplore.ieee.org/document/1334672/},
volume = {3},
year = {2004}
}
@inproceedings{Kimura2003,
abstract = {We propose a new feature dimension reduction method for multimedia search. The main technique in the method is dynamic segmentation that partitions sequential feature trajectories dynamically. While dynamic segmentation reduces the average dimensionality and accelerates the search, it requires huge amount of calculation. Thus, our method quickly executes suboptimal partitioning of the trajectories by using the discreteness of dimension changes. This guarantees the optimal amount of calculation to derive the suboptimal partitioning under the condition that the dimension monotonously increases as the segment length increases. The experiment shows that our method is over 10 times faster than a straightforward dynamic segmentation method.},
author = {Kimura, Akisato and Kashino, Kunio and Kurozumi, Takayuki and Murase, Hiroshi},
booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2003.1221635},
isbn = {0-7803-7965-9},
pages = {II--389},
publisher = {IEEE},
title = {{Dynamic-segmentation-based feature dimension reduction for quick audio/video searching}},
url = {http://ieeexplore.ieee.org/document/1221635/},
volume = {3},
year = {2003}
}
@incollection{2003,
author = {木村, 昭悟 and 柏野, 邦夫 and 黒住, 隆行 and 村瀬, 洋},
journal = {画像ラボ},
number = {11},
pages = {60--67},
title = {グローバルな枝刈りを導入した音や映像の高速探索},
volume = {14},
year = {2003}
}
@article{2002,
abstract = {探したい音や映像が具体的に与えられ,それとほぼ同じ信号の区間が蓄積された長時間の音や映像の中のどこにあるかを高速に探索する問題に対する新しい手法を提案する.これまでに,高速探索手法の一つとして,時系列アクティブ探索法が提案されている.これは,信号から抽出したヒストグラムに基づく信号探索手法であり,ローカルな枝刈り,すなわち照合窓周辺の類似度に基づいて探索の必要がない区間の照合を省くことにより高速な探索を実現していた.それに対し,提案手法は,ローカルな枝刈りに加え,信号全体の類似性に基づくヒストグラムの分類により信号時系列全体を見て探索の必要がない区間を取り除く,グローバルな枝刈りを導入することにより,更に高速な探索を実現する.本論文では,グローバルな枝刈りの度合と保証される精度との関係を詳しく議論する.例えば提案手法では,128次元のヒストグラムを1024通りに分類したとき,時系列アクティブ探索法に比べ,事前処理の計算時間が信号時系列の再生時間の1{\%}程度増加するものの,同程度の精度を保ったまま,探索速度を約9倍にできることを実験により示す.},
author = {木村, 昭悟 and 柏野, 邦夫 and 黒住, 隆行 and 村瀬, 洋},
issn = {09151923},
journal = {電子情報通信学会論文誌 D-II},
keywords = {L{\_}2距離,グローバルな枝刈り,ヒストグラム重なり率,一致探索,時系列アクティブ探索法},
number = {10},
pages = {1552--1562},
publisher = {社団法人電子情報通信学会},
title = {グローバルな枝刈りを導入した音や映像の高速探索},
url = {http://ci.nii.ac.jp/naid/110004066695/},
volume = {85},
year = {2002}
}
@inproceedings{Kimura2002,
abstract = {We propose a quick algorithm for multimedia signal search. The algorithm comprises two techniques: feature compression based on piecewise linear maps and distance bounding to efficiently limit the search space. When compared with existing multimedia search techniques, they greatly reduce the computational cost required in searching. Although feature compression is employed in our method, our bounding technique mathematically guarantees the same recall rate as the search based on the original features; no segment to be detected is missed. Experiments indicate that the proposed algorithm is approximately 10 times faster than and as accurate as an existing fast method maitaining the same search accuracy.},
author = {Kimura, Akisato and Kashino, Kunio and Kurozumi, Takayuki and Murase, Hiroshi},
booktitle = {IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2002.5745448},
isbn = {0-7803-7402-9},
month = {may},
pages = {3656--3659},
publisher = {IEEE},
title = {{A quick search method for multimedia signals using feature compression based on piecewise linear maps}},
url = {http://ieeexplore.ieee.org/document/5745448/},
volume = {4},
year = {2002}
}
@inproceedings{Kimura2001,
abstract = {Previously, we proposed a histogram-based quick signal search method called Time-Series Active Search (TAS). TAS is a method of searching through long audio or video recordings for a specified segment, based on signal similarity. TAS is fast; it can search through a 24-hour recording in 1 second after a query-independent preprocessing. However, an even faster method is required when we consider a huge amount of audio archives, for example a month's worth of recordings. Thus, we propose a preprocessing method that significantly accelerates TAS. The core part of this method comprises a global histogram clustering of long signals and a pruning scheme using those clusters. Tests using broadcast recording indicate that the proposed algorithm achieves a search speed approximately 3 to 30 times faster than TAS. In these tests, the search results are exactly the same as with TAS.},
author = {Kimura, Akisato and Kashino, Kunio and Kurozumi, Takayuki and Murase, Hiroshi},
booktitle = {IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2001.941198},
isbn = {0-7803-7041-4},
pages = {1429--1432},
publisher = {IEEE},
title = {{Very quick audio searching: introducing global pruning to the Time-Series Active Search}},
url = {http://ieeexplore.ieee.org/document/941198/},
volume = {3},
year = {2001}
}
@inproceedings{Kimura2001a,
abstract = {Slepian and Wolf first considered the data compression of correlated sources called the SW system, where two sequences emitted from correlated sources are separately encoded to codewords, and sent to a single decoder which has to output original sequence pairs. Recently, Oohama has extended the SW system and investigated a more general case where there are some mutual linkages between two encoders of the SW system. In this paper, we investigate variable-length coding which allows asymptotically vanishing probability of error for the system considered by Oohama. We clarify the admissible rate region for mixed sources characterized by two ergodic sources, and show that this region is strictly wider than that for fixed-length codes.},
author = {Kimura, Akisato and Uyematsu, Tomohiko},
booktitle = {IEEE Information Theory Workshop (ITW)},
doi = {10.1109/ITW.2001.955143},
isbn = {0-7803-7119-4},
pages = {82--84},
publisher = {IEEE},
title = {{Weak variable-length Slepian-Wolf coding with linked encoders for mixed sources}},
url = {http://ieeexplore.ieee.org/document/955143/},
year = {2001}
}
@inproceedings{Kimura1999,
author = {Kimura, Akisato and Uyematsu, Tomohiko},
booktitle = {Memorial Workshop for the 50th Anniversary of the Shannon Theory},
pages = {1--4},
title = {{Large deviations performance of interval algorithm for random number generation}},
year = {1999}
}
@inproceedings{takai1998cmos,
abstract = {A new CMOS companding current-mode integrator is proposed. The companding integrator is based on the MOS translinear principle and utilizing the nature of the MOSFET square-law. SPICE simulation results demonstrate good performances.},
author = {Takai, Nobukazu and Kimura, Akisato and Fujii, Nobuo},
booktitle = {IEEE Asia-Pacific Conference on Circuits and Systems (APCCS)},
doi = {10.1109/APCCAS.1998.743647},
isbn = {0-7803-5146-0},
organization = {IEEE},
pages = {17--20},
publisher = {IEEE},
title = {{CMOS FET companding current-mode integrator}},
url = {http://ieeexplore.ieee.org/document/743647/},
year = {1998}
}
